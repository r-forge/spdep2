%Sweave("spatial_inla.Rnw", encoding="UTF-8", keep.source=FALSE)
%system("pdflatex spatial_inla.tex")
%system("bibtex spatial_inla")
\documentclass[article]{jss}

\usepackage{thumbpdf}
\usepackage{amssymb}
%% need no \usepackage{Sweave.sty}



<<echo=FALSE>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
@


<<echo=FALSE>>=
#TRUE: Run all models
#FALSE: Download results from author's website for Leroux and spatial 
#	econometrics models
runmodels<-FALSE#TRUE

#When runmodels==TRUE
#> system.time(  Sweave("spatial_inla.Rnw") )
#  user  system elapsed 
#779.976  41.545 536.349 
#
#model name	: Intel(R) Core(TM)2 Duo CPU     E7500  @ 2.93GHz
#TWO cores

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Roger S. Bivand\\NHH Norwegian\\ School of Economics \And 
Virgilio G\'omez-Rubio\\Universidad de\\ Castilla-La Mancha 
\And H\r{a}vard Rue\\Norwegian University for\\ Science and Technology
%Achim Zeileis\\Universit\"at Innsbruck \And 
%        Second Author\\Plus Affiliation}
}
\title{Extending the \pkg{R-INLA} Package for Spatial Statistics}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Roger S. Bivand, Virgilio G\'omez-Rubio, H\r{a}vard Rue}
\Plaintitle{Extending the R-INLA Package for Spatial Statistics}
%\Shorttitle{} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The Integrated Nested Laplace Approximation (INLA) provides an interesting
way of approximating the posterior marginals of a wide range of Bayesian
hierarchical models. This approximation is based on conducting a 
Laplace approximation of certain functions and numerical integration is
extensively used to integrate some of the models parameters out. 

INLA is implemented in the \pkg{R-INLA} package, which provides a suitable
interface for data analysis. Although the INLA methodology can deal with
a large number of models, only the most relevant have been implemented
within \pkg{R-INLA}. However, many other important models are not available
for \pkg{R-INLA} yet.

In this paper we show how to extend the number of latent models available
for the model parameters. Our approach is based on conditioning on one
or several model parameters and fit these conditioned models with \pkg{R-INLA}.
Then these models are combined using Bayesian Models Averaging to provide
the final approximations to the posterior marginals of the model.

Finally, we show some examples of the application of this technique
in spatial statistics. It is worth noting that our approach can be extended
to a number of other fields, and not only spatial statistics.


}
\Keywords{INLA, spatial statistics, \proglang{R}}
\Plainkeywords{INLA, spatial statistics, R}
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
Roger S. Bivand\\
Department of Economics\\
NHH Norwegian School of Economics\\
Helleveien 30\\
N-5045 Bergen, Norway\\
 \\
%}
%\Address{
Virgilio G\'omez-Rubio\\
Department of Mathematics\\
School of Industrial Engineering\\
University of Castilla-La Mancha\\
02071 Albacete, Spain\\
 \\
%}
%\Address{
H\r{a}vard Rue\\
Department of Mathematical Sciences\\
Norwegian University for Science and Technology\\
N-7491 Trondheim, Norway
}

\begin{document}

\section[Introduction]{Introduction}


Bayesian inference has become very popular in spatial statistics in recent
years. Part of this success is due to the availability of computation methods
to tackle fitting of spatial models. \citet{besagetal:1991} proposed in their
seminal paper an appropriate way of fitting a spatial model using Markov Chain
Monte Carlo methods. This model have been extensively used and extended to
consider different types of fixed and random effects for spatial and
spatio-temporal analysis.

In general, fitting these models have been possible because of the availability
of different computational techniques, the most notable being Markov Chain
Monte Carlo. For large models or big data sets, MCMC can be tedious and
reaching the required number of samples can take a long time. Not to mention
that autocorrelation may arise and that an increased number of iterations may
be required.

Alternatively, the posterior distributions of the parameters could be
approximated in some way. However, most models are highly multivariate and
approximating the full posterior distribution may not be possible in practice.
The Integrated Nested Laplace Approximation \citep[][INLA]{isi:000264374200002} focuses on
the posterior marginals for latent Gaussian models. Although these may seem
a strong constraint, these models appear in a good number of fields. 
Hence, INLA will be particularly useful when  only
marginal inference on the model parameters is needed.

The \pkg{R-INLA} package \citep{rinla:2013} for the \proglang{R} programming language provides
an implementation of INLA so that models can be fitted using standard 
\proglang{R} commands. Results are readily available for plotting or
further analysis. Although INLA is a general method to approximate the
posterior marginals, \pkg{R-INLA} implements a few latent models and prior
distributions for the model parameters.
This may be a drawback, as it is difficult to fit new models with INLA if these
are based on other distributions not available in \pkg{R-INLA}.  This may be an
inconvenience when trying to develop new models as there is no easy way of
extending \pkg{R-INLA} to fit other models.

We have devised a way of extending the number of models that \pkg{R-INLA} can
fit with little extra effort. First of all, we consider one (or more)
parameters in our model so that, if they are fixed, the resulting model can be
fitted with \pkg{R-INLA}. What we are doing here is, in fact, to fit a model
conditioned on the assigned values to the parameters. Then, we can assign
different values to these parameters and combine the resulting models in some
way to obtain a fit of the original model. We have used Bayesian Model
Averaging and numerical integration techniques to combine these models.


This paper is organised as follows. Section~\ref{sec:INLA} describes the
Integrated Nested Laplace Approximation.  In Section~\ref{sec:spmodels} the
different latent models for spatial statistics are described.  We describe how
to extend \pkg{R-INLA} to fit new models in Section~\ref{sec:extINLA}. Some
examples are provided in Section~\ref{sec:examples}.  Finally, we discuss why
our approach is relevant in Section~\ref{sec:disc}.

\section{Integrated nested Laplace approximation}
\label{sec:INLA}

Bayesian inference is based on computing the posterior distribution of a
vector of model parameters $\mathbf{x}$ conditioned on the vector of observed
data $\mathbf{y}$. Bayes' rule states that this posterior distribution
can be written down as

\begin{equation}
\pi(\mathbf{x}|\mathbf{y}) \propto \pi(\mathbf{y}|\mathbf{x}) \pi(\mathbf{x})
\end{equation}
\noindent
Here, $\pi(\mathbf{y}|\mathbf{x})$ is the likelihood of the model and
$\pi(\mathbf{x})$ represents the prior distribution on the model parameters.


Usually, $\pi(\mathbf{x}|\mathbf{y})$ is a highly multivariate distribution
and difficult to obtain. In particular, it is seldom possible to derive it in
a closed form. For this reason, several computational approaches  have been 
proposed to get approximations to it. MCMC is probably the most widely used
family of computational approaches to estimate the posterior distribution.

The marginal distribution of parameter $x_i$ can be denoted by
$\pi(x_i|\mathbf{y})$ and it can be easily derived from the full posterior by
integrating out over the remaining set of parameters $\mathbf{x}_{-i}$.

Let us assume that we have a set of $n$ observations 
$\mathbf{y}=\{y_i\}_ {i=1}^n$, whose distribution is of the Exponential family.
The mean of observation $i$ is $\mu_i$, which is modelled using a linear
predictor $\eta_i$ as follows:

\begin{equation}
\eta_i=\alpha+\sum_{j=1}^{n_f} f^{(j)}(u_{ji})+\sum_{k=1}^{n_{\beta}}\beta_k z_{ki}+\varepsilon_i
\end{equation}
\noindent
$\alpha$ is the intercept, $f^{(j)}$ are functions on a set of $n_f$ random
effects on a vector of covariates $\mathbf{u}$, $\beta_k$ are coefficients on
some covariates $\mathbf{z}$ and $\varepsilon_i$ are error terms. Hence, the
vector of latent effects is $\mathbf{x}=\{\{\eta_i\}, \alpha, \{\beta_k\},
\ldots\}$. Note that given our particular interest in spatial models, terms
$f^{(j)}(u_{ji})$ can be defined as to model spatial or spatio-temporal
dependence.

$\mathbf{x}$ is modelled using a Gaussian distribution with zero mean and
variance-covariance matrix $Q(\theta_1)$. Now, $\theta_1$ is a vector of
hyperparameters. Furthermore, $\mathbf{x}$ is supposed to be a Gaussian Markov
Random Field \citep[GMRF,][]{rueheld:2005}. This means that  $Q(\theta_1)$ will fulfil a number of
Markov properties. 
%This will make $y_i$ independent given $x_i$ and $\theta$.

The distribution of observations $y_i$ will depend on the latent effects
$\mathbf{x}$ and, possibly, a number of hyperparameters $\theta_2$.  Taking
the vector of hyperparameters $\theta=(\theta_1, \theta_2)$, observations
$y_i$ will be independent of each other $x_i$ and $\theta$ because
of $\mathbf{x}$ being a GMRF.

Following \citet{isi:000264374200002}, the posterior distribution of the model
latent effects $\mathbf{x}$ and hyperparameters $\theta$ can be written as 

\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}) \propto
\pi(\mathbf{\theta}) \pi(\mathbf{x}|\mathbf{\theta})\prod_{i\in \mathcal{I}}\pi(y_i|x_i,\mathbf{\theta})
\propto 
\end{equation}

\begin{equation}
\pi(\mathbf{\theta}) |\mathbf{Q}(\mathbf{\theta})|^{n/2} \exp\{-\frac{1}{2}\mathbf{x}^T \mathbf{Q}(\mathbf{\theta}) \mathbf{x}+\sum_{i\in\mathcal{I}} \log(\pi(y_i|x_i, \mathbf{\theta}) \}
\end{equation}
\noindent
$\mathcal{I}$ represents an index of observed data (from 1 to $n$),
$\mathbf{Q}(\mathbf{\theta})$ is a variance-covariance matrix on some
hyperparameters $\theta$ and $\log(\pi(y_i|x_i, \mathbf{\theta}) \}$ is
the log-likelihood of observation $y_i$.

INLA allows different forms for the likelihood of the observations.  This
includes not only distributions from the Exponential family but also mixtures
of distributions. Also, INLA can handle observations with different likelihoods
in the same model. Regarding the latent effects $\mathbf{x}$, different models
can be used. We will describe some of these in more detail in
Section~\ref{sec:spmodels}.


The specification of the prior distributions $\pi(\theta)$ is also very 
flexible. These will often depend on the latent effect but, in principle,
the most common distributions are available and the user can define its
own prior distribution in the \pkg{R-INLA} package (but we will come
back to this later). 

Hence, we can write the marginals distributions of the elements in $\mathbf{x}$
and $\mathbf{\theta}$ (i.e., latent effects and hyper-parameters) as


\begin{equation}
\pi(x_i|\mathbf{y}) \propto \int \pi(x_i|\mathbf{\theta}, \mathbf{y})  \pi(\mathbf{\theta}| \mathbf{y}) d\mathbf{\theta}
\end{equation}
\noindent
and

\begin{equation}
\pi(\theta_j|\mathbf{y}) \propto \int \pi(\mathbf{\theta}| \mathbf{y})  d\mathbf{\theta}_{-j} 
\end{equation}

In order to estimate the previous marginals, we need 
$\pi(\mathbf{\theta}|\mathbf{y})$ or, alternatively, a convenient
approximation that we will denote by $\tilde\pi(\theta|\mathbf{y})$.
Initially, this approximation can be taken as

\begin{equation}
\tilde\pi(\mathbf{\theta}|\mathbf{y})\propto 
\frac{\pi(\mathbf{x},\mathbf{\theta},\mathbf{y})}{\tilde\pi_G(\mathbf{x}|\mathbf{\theta},\mathbf{y})}\bigg|_{x=x^*(\theta)}
\end{equation}
\noindent
Here 
$\tilde\pi_G(\mathbf{x}|\mathbf{\theta},\mathbf{y})$ is a Gaussian
approximation to the full conditional of $\mathbf{x}$ and $x^*(\theta)$
is the mode of the full conditional for a given value of $\mathbf{\theta}$.
\citet{isi:000264374200002} take this approximation and use it 
to compute the marginal distribution of $x_i$ using numerical integration:

\begin{equation}
\tilde\pi(x_i|\mathbf{y})= 
\sum_k \tilde\pi (x_i|\mathbf{\theta}_k, \mathbf{y})\times 
\tilde\pi(\mathbf{\theta}_k|\mathbf{y})\times \Delta_k
\end{equation}
\noindent
Here $\Delta_k$ are the weights associated to vector of values
$\mathbf{\theta}_k$ in a grid for vector of hyperparameters .

%\citet{isi:000264374200002}  also discuss how the approximation $\tilde\pi
%(x_i|\mathbf{\theta}_k, \mathbf{y})$ should be in order to reduce numerical
%error and they provide different alternatives.

Note that in the previous equation it is important to have good approximations
to $\pi (x_i|\mathbf{\theta}_k, \mathbf{y})$. A Gaussian approximation
$\tilde\pi_G (x_i|\mathbf{\theta}_k, \mathbf{y})$, with mean $\mu_i(\theta)$
and variance $\sigma^2_i(\theta)$, may be a good starting point but a better
approximation may be required in other cases. \citet{isi:000264374200002}
developed better approximations based on alternative approximation methods,
such as the Laplace Approximation.  For example, they have used the Laplace
Approximation to obtain:

\begin{equation}
\tilde\pi_{LA}(x_i|\mathbf{\theta}, \mathbf{y}) \propto 
\frac{\pi(\mathbf{x}, \mathbf{\theta}, \mathbf{y})}
{\tilde\pi_{GG}(\mathbf{x}_{-i}|x_i, \mathbf{\theta}, \mathbf{y})}
\bigg|_{\mathbf{x}_{-i}=\mathbf{x}^*_{-i}(x_i, \mathbf{\theta})}
\end{equation}
\noindent
$\tilde\pi_{GG}(\mathbf{x}_{-i}|x_i, \mathbf{\theta}, \mathbf{y})$ is a
Gaussian  approximation to $\mathbf{x}_{-i}|x_i, \mathbf{\theta}, \mathbf{y}$
around its mode $\mathbf{x}^*_{-i}(x_i, \mathbf{\theta})$.

\citet{isi:000264374200002} develop a Simplified Laplace Approximation to
improve $\tilde\pi_{LA}(x_i|\mathbf{\theta}, \mathbf{y})$ using a series
expansion of the Laplace Approximation around $x_i$. This approximation is
computationally less expensive, and it also corrects for location and
skewness.


\subsection[The R-INLA package]{The \pkg{R-INLA} package}

INLA has been implemented as an \proglang{R} package called \pkg{R-INLA},
which can be downloaded from \url{http://www.r-inla.org/}. \pkg{R-INLA}
provides an interface similar to the one used to fit Generalised Additive
Models with function \code{gam()}. It can handle fixed effects, non-linear terms
and random effects in a \code{formula} argument. The interface is flexible
enough to allow for the specification of different priors and model fitting
options. Non-linear terms and random effects are included in the formula as
calls to the \code{f()} function. 


The model is fitted with a call to function \code{inla()}, which will return an
\code{inla} object with the fitted model. Note that, by default, only a number
of results will be returned. These includes the marginal distributions of
the latent effects and hyperparameters. 


In addition to the posterior marginals, \pkg{R-INLA} can provide a number
of additional quantities on the fitted model. For example, it can 
provide the log-marginal likelihood $\pi(\mathbf{y})$ which can be used
for model selection. Other model selection criteria such as the DIC 
\citep{Spiegelhalteretal:2002} and CPO \citep{Heldetal:2010} have also
been implemented.

Furthermore, \pkg{R-INLA} includes a number of options to define the
prior distributions for the parameters in the model. Well-known
prior distributions are available and the user can define his own prior
distributions as well.

In the next Section we describe different examples of the use of
\pkg{R-INLA} for spatial statistics. Therein we have included
a detailed description on how \code{inla()} should be called.

\section{Spatial models with INLA} \label{sec:spmodels}


As discussed in Section~\ref{sec:INLA}, spatial dependence can be included as
part of the vector of latent effects $\mathbf{x}$. In principle, any number of
random effects can be included in the model. In this Section, we will describe
the different options available, depending on the type of problem. A full
description of the models described here can be found in the \pkg{R-INLA}
website at \url{http://www.r-inla.org}, but we have included a summary.
\citet{Blangiardoetal:2013} and \citet{GomezRubioetal:2013} also discuss
the different spatial models included in \pkg{R-INLA}.

\subsection{Analysis of lattice data}

First of all, we will discuss the analysis of lattice data because this will
set the basis for other types of analyses. In the analysis of lattice data
observations are grouped according to a set of areas, which usually represent
some sort of administrative region (neighbourhoods, municipalities, provinces,
countries, etc.).

\pkg{R-INLA} includes a latent model for uncorrelated random effects. In
this case, the random effects $u_i$ are modelled as

\begin{equation}
u_i \sim N(0, \tau_u)
\end{equation}
\noindent
where $\tau_u$ refers to the precision of the Gaussian distribution.  It should
be noted that \pkg{R-INLA} assigns a prior to $\log(\tau_u)$ which, by default,
is a log-Gamma  distribution.  Although this model is not spatial, it can be
combined with other spatial models.


In order to model spatial correlation, neighbourhood must be set among the
study areas.  It is often considered that two areas are neighbours is they
share a common boundary.  Spatial autocorrelation is modelled using a Gaussian
distribution with zero mean and a precision matrix that will model
correlation between neighbours. Given that latent effects are GMRF, 
we can define the variance-covariance matrix of the random effects
as

\begin{equation}
\Sigma = \frac{1}{\tau} Q^{-1}
\end{equation}
\noindent
where $\tau$ is a common precision parameter and matrix $Q$ encodes
the spatial structure. Given that we are assuming a latent GMRF, this also
means that matrix $Q$ will be defined such as element $Q_{ij}$ is zero if
areas $i$ and $j$ are not neighbours. This means that $Q$ is often a very
sparse matrix. See, for example, \citet{rueheld:2005} 
for details.

Available specifications for spatial dependence includes the intrinsic CAR
specification \citep{besagetal:1991}. This will produce a $Q$ matrix in which
element $Q_{ii}$ is $n_i$ (the number of neighbours of area $i$) and element
$Q_{ij}$ (with $i\neq j$) is -1 if areas $i$ and $j$ are neighbours and 0 otherwise. This
means that the spatial random effects $v_i$ are distributed as

\begin{equation}
v_i|v_j,\tau_v \sim  N( \frac{1}{n_i}\sum_{i\sim j} v_j, \frac{1}{\tau_vn_i})\ \  i\neq j
\end{equation}
\noindent
$\tau_v$ is the conditional precision of the random effects. As in the previous
model, \pkg{R-INLA} uses a Gaussian prior on $\log(\tau_v)$.

In addition, a proper version of this model is available as well,
for which the spatial random effects are distributed as

\begin{equation}
v_i|v_j,\tau_v \sim  N( \frac{1}{n_i+d}\sum_{i\sim j} v_j, \frac{1}{\tau_v(n_i+d)})\ \ i\neq j
\end{equation}
\noindent
$d$ is a positive quantity to make the distribution proper. By default,
a log-Gamma distribution is assigned to $\log(d)$.

A more general approach is obtained  with the following precision
matrix:

\begin{equation}
Q = (I - \frac{\rho}{\lambda_{max}}C)
\end{equation}
\noindent
Here $I$ is the identity matrix, $\rho$ a spatial autocorrelation parameter,
$C$ an adjacency matrix and $\lambda_{max}$ the maximum eigenvalue of $C$.
This specification ensures that $\rho$ takes values between 0 and 1.
\pkg{R-INLA} assigns a Gaussian prior on $\log(\rho/(1-\rho))$.

In the following example we use the \code{boston} data set from the
\proglang{R} package \pkg{spdep} \citep{spdep:2013} to develop an example on several spatial
models.  This data set  records median price for houses that were occupied by
their owners plus some other relevant covariates \citep[see,][for
details]{HarrisonRubinfeld:1978}. Data have been recorded at the tract level
and the neighbourhood structure of the tracts is also available.
We have converted this into a binary matrix to be used with \pkg{R-INLA}
using function \code{nb2mat}. This will be passed to function \code{f()} when
defining the spatial model.


<<>>=
library("spdep")
data("boston")

adj <- nb2mat(boston.soi, style = "B")
@



A summary of some latent models implemented in \pkg{R-INLA}, and that can be
used within the \code{f()} function, is available in
Table~\ref{tab:inlamodels}. Note that this is not an exhaustive list and that a
complete list of the available latent models can be obtained from the
\pkg{R-INLA} documentation. Also, detailed examples are available from the
\pkg{R-INLA} website at \url{http://www.r-inla.org}.


\begin{table}[h]
\begin{center}
\begin{tabular}{ll}
Name in \code{f()}  & Model \\
\hline
\code{besag} & Intrinsic CAR\\
\code{besagproper} & Proper CAR\\ 
\code{bym} & Convolution model \\
\code{rw2d} & 2-D random walk \\
%\hline[.25cm]
\code{generic0} & $\Sigma=\frac{1}{\tau}Q^{-1}$ \\[.25cm]
\code{generic1} & $\Sigma=\frac{1}{\tau}(I_n-\frac{\rho}{\lambda_max}C)^{-1}$
%\code{rw2d} & Random walk of order 2
\end{tabular}
\end{center}
\caption{Summary of some latent models implemented in \pkg{R-INLA} 
for spatial statistics.}
\label{tab:inlamodels}
\end{table}



The model that we are fitting is:

\begin{equation}
y_i = \alpha+\beta X + v_i +\varepsilon_i
\end{equation}
\noindent
where $\alpha$ is the model intercept, $\beta$ a vector of coefficients of the
covariates, $v_i$ a random effect with an intrinsic CAR specification and
$\varepsilon_i$ is random Gaussian error term. As \code{f()} needs an area
index which must have different values for different areas, this is first
defined in variable \code{idx}.

<<>>=
library("INLA")

boston.c$idx <- 1 : nrow(boston.c)
form <- log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2) +  
AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)+
f(idx, model = "besag", graph = adj )

m1 <- inla(form, data = boston.c)
@

Note how the call to \code{inla()} is similar to fitting other regression
models with \proglang{R} with \code{glm()} or \code{gam()}. Furthermore, 
it is very easy to include spatial random effects with function \code{f()}
in the \code{formula} passed to \code{inla()}.


A summary of the model can be obtained as
follows:

<<>>=
summary(m1)
@
\noindent
The output includes summary statistics of the posterior marginals of the
coefficients of the fixed effects plus the precisions of the error term and
instrinsic CAR random effect. Figure~\ref{fig:marg1} shows the estimated
marginals of the precisions in the model.

\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, width=8, height=8>>=
par(mfrow=c(2,1))
plot(m1$marginals.hyperpar[[1]], xlim=c(0, 2000), type="l",
   main="Precision of error term")
plot(m1$marginals.hyperpar[[2]], xlim=c(0,50), type="l", 
   main="Precision of spatial random effects")

@
\end{center}
\caption{Marginals of the precisions of the error term (top) and
spatial random effects (bottom), Boston housing data.}
\label{fig:marg1}
\end{figure}


\subsection{Point patterns}

Point patterns are analysed with INLA as the result of a counting process,
i.e., points are not modelled directly but they are aggregated over a a grid
of small squares. For this reason, the analysis of point patterns is conducted
similarly to that of lattice data: counts are available for each square and 
these are assigned neighbours according to the adjacent squares. Then, counts
can be smoothed using an appropriate non-linear term, such as spatial
random effects.

In the following example we use the Japanese black pine data set from
\proglang{R} package \pkg{spatstat} \citep{spatstat:2005}. This data set records the location of
Japanese black pine saplings in a square sampling in a natural forest.  This
is example is reproduced from \citet{GomezRubioetal:2013}.

Hence, we first split the study area into smaller squares to create a
grid of $10\times 10$ squares.
%, and the we aggregate the pines over the grid of $10\times 10$ squares. 

<<results=hide, keep.source=TRUE>>=
library("spatstat")
data("japanesepines")

japd <- as.data.frame(japanesepines)

nrow <- 10
ncol <- 10
n <- nrow * ncol

grd <- GridTopology(
   cellcentre.offset = c(0, 0),
   cellsize = c(1 / 9, 1 / 9), cells.dim = c(nrow, ncol)
)
@


After the creation of the grid, we have used function \code{over()} on
the set of points and the newlydefined squares to find how many points can be
found in each square.

<<>>=
polygrdjap <- as(grd, "SpatialPolygons")
idxpp <- over(SpatialPoints(japd), polygrdjap)

japgrd <- SpatialGridDataFrame(grd, data.frame( Ntrees = rep(0, n) ) )

tidxpp <- table(idxpp)
japgrd$Ntrees[ as.numeric( names(tidxpp) ) ] <- tidxpp
@


Next, an index variable is built to create the spatial neighbourhood structure
to be passed to the \code{f()} function. Note that care must be taken as
\proglang{R} and \pkg{R-INLA} may have a different ordering of the areas when
defining the adjacency matrix.

<<results=hide, keep.source=TRUE>>=
japgrd$SPIDX <- 1 : n

japnb <- poly2nb(polygrdjap)

adjpine <- nb2mat(japnb, style = "B")
@

Finally, we define the call to \code{inla()} using a \code{formula} which
includes spatial random effects based on the grid of squares.  In addition, we
have set other options to compute the DIC, with
\code{control.compute=list(dic=TRUE)}, and the marginals of the linear
predictors, using \code{control.predictor=list(compute=TRUE)}.
We have included the specification of the prior distributions of
the log-precisions of unstructured and spatial random effects as well.

<<keep.source=TRUE>>=
fpp  <-  Ntrees ~ 1 + f(japgrd$SPIDX, model = "bym", graph = adjpine,
  hyper=list(prec.unstruct=list(prior="loggamma", param=c(0.001, 0.001) ),
                prec.spatial=list(prior="loggamma", param=c(0.1,0.1) ))
)

japinlala <- inla(fpp,
   family = "poisson", data = as.data.frame(japgrd),
   control.compute = list(dic = TRUE),
   control.inla=list(tolerance=1e-20, h=1e-8),
   control.predictor = list(compute = TRUE)
)

japgrd$INLALA <-  japinlala$summary.fitted.values[, 1]
@
\noindent
Figure~\ref{fig:sppa} shows the original counts and the smoothed counts.  Note
that this is similar to estimating the intensity of an inhomogeneous point
pattern using a smoothing method.


\begin{figure}[h]
\begin{center}
<<fig=TRUE, echo=FALSE, height=4, width=8>>=
print(spplot(japgrd, c("Ntrees", "INLALA"),
   #at=c(0.6, 0.9801, 1.055, 1.087, 1.125, 1.6),
  cuts=10,
   col.regions=gray.colors(10+1, 0.9, 0.4),
   names.attr=c("DATA", "INLA"),
   par.strip.text=list(cex=1),
   sp.layout=list(list("sp.points", SpatialPoints(coords(japanesepines))))
))
@
\end{center}
\caption{Estimation of the intensity of a point pattern with \pkg{R-INLA}, 
Japanese black pine dataset.}
\label{fig:sppa}
\end{figure}



\subsection{Geostatistics}


\pkg{R-INLA} deals with geostatistical data on a regular grid. This means
that observations need to be matched to the points in the grid and that those
points with no observations attached are considered as missing values.
Hence, this is somewhat similar to the analysis of lattice data and point
patterns. However, \pkg{R-INLA} provides a number of options to build 
model-based geostatistical models \citep{DiggleRibeiro:2007}. First
of all, different likelihoods can be used. Secondly, there are different
options to define the spatial random effects. Although it is still possible
to model spatial dependence in the grid of points using a CAR specification,
\pkg{R-INLA} provides a two-dimensional Mat\'ern covariance function. 


This correlation allows, for example, the use of exponentially decaying
functions such as 

\begin{equation}
\Sigma_{ij} = \sigma^2 \exp(-d_{ij}/\varphi)
\end{equation}
\noindent
where $d_{ij}$ is the distance between points $i$ and $j$, and $\varphi$
is a parameter that controls the scale of the spatial dependence.


%
%IMPORTANT: Change the text if used in the paper
%
%In this case, the variance-covariance matrix is defined as 
%
%$$
%\Sigma_{ij}= \sigma^2 \frac{\tau^{\kappa} K(\tau, \kappa)}{2^{\kappa-1} \Gamma(\kappa)}; \tau = \alpha_{\kappa}d_{ij}/\varphi
%$$
%\noindent
%$K(\cdot, \kappa)$ is the modified Bessel function of order $\kappa$ and
%$\Gamma(\cdot)$ the Gamma function. $\alpha_{\kappa}$ and $\varphi$ can be used
%to control the scale of the spatial variation. Setting $\kappa$ to $0.5$
%leads to an exponential covariance. Other values of $\kappa$ will lead
%to other known spatial covariance functions \citep{ISI:000263326600001}.



More recently, \citet{Lindgren:2011} follow a different approach based on
a triangulation on the sampling points and the use of stochastic partial
differential equations. Now, the spatial effects are defined as

\begin{equation}
u(s)=\sum_{k=1}^n \psi_k(s)w_k,\ s\in \mathbb{R}^2
\end{equation}
\noindent
Here, $\{\psi_k(s)\}$ are a basis of functions and $w_k$ are associated
weights. Weights are assumed to be Gaussian. The advantages of this approach
for spatial statistics are fully described in \citet{Camelettietal:2013}.


In order to show how to fit geostatistical models with \pkg{R-INLA} we
reproduce here an example from \citet{GomezRubioetal:2013} based on the
Rongelap data set \citep{DiggleRibeiro:2007}, which records  radionuclide
concentration at 157 different locations in Rongelap island. We have restricted
the analysis to one of the clusters in the north-east part of the island
because observations need to be matched to a regular grid of points.  For this
analysis we have used \proglang{R} packages \pkg{geoR} \citep{geoR:2001} and
\pkg{geoRglm} \citep{geoRglm:2002}.



First of all, data are loaded and the data from the desired clusters
are extracted from the original data set by checking that their coordinates
are in the window $(-700, -500)\times (-1900, -1700)$.

<<keep.source=TRUE>>=
library("geoR")
library("geoRglm")

data("rongelap")

rgldata <- as.data.frame(rongelap)
xy <- rongelap[[1]]

idx1 <- (xy[,1] < -500 & xy[,1] > -700 & 
   xy[,2] > -1900 & xy[,2] < -1700)

rgldata <- rgldata[idx1, ]
@


The following step is to  define the grid topology for the grid that will be
used to match these points to. The grid is defined to be of dimension 
$5\times 5$. 

<<keep.source=TRUE>>=
nrow <- 5
ncol <- 5
n <- nrow * ncol

grdoffset <- c( min(rgldata$X1), min(rgldata$X2) )
csize1 <- diff( range(rgldata$X1) ) / (nrow-1)
csize2 <- diff( range(rgldata$X2) ) / (ncol-1)
grd <- GridTopology(
   cellcentre.offset = grdoffset, 
   cellsize = c(csize1, csize2),
   cells.dim = c(nrow, ncol)
)
@
\noindent
Data will be placed in a \code{SpatialGridDataFrame} (using the previously
defined grid topology) and re-organised according to what \pkg{R-INLA} expects
for this model (i.e., grid data stored by column).  An index variable \code{IDX}
is added to be used in \code{f()} when defining the model. However, 
\pkg{R-INLA} will rely on how the rows are ordered in the data passed to 
\code{inla()} when defining distances and adjacencies (i.e., the index
variable ordering will not be considered).

<<>>=
inla2sp <- inla.lattice2node.mapping(nrow, ncol)[ , ncol:1]
inla2sp <- as.vector(inla2sp)

spgrd <- SpatialGridDataFrame(grd, as.data.frame(rgldata[inla2sp, ]) )

spgrd$IDX <- 1 : nrow(spgrd@data)
@


Next, we create a \code{SpatialPolygons} with the boudanries of the squares
in the grid. This way, it is easy to match the data to the newly created grid using function
\code{over()}.


<<>>=
polygrd <- as(grd, "SpatialPolygons")

dataidx <- over(SpatialPoints( as.matrix(rgldata[, 1:2]) ), polygrd)
@

It should be noted that  radionuclide concentration is measured at each square
by the average of the observations in the square, and this needs
to be computed beforehand.


<<>>=
yag <- by(rgldata$data, dataidx, sum)
umag <- by(rgldata$units.m, dataidx, sum)
ratioag <- yag / umag
@

Then, a new column is added to the \code{SpatialGridDataFrame} with these
averages.\code{NA} will be used for
the squares with no data so that these values will be imputed from the model.
<<>>=
spgrd$ratioag <- NA
spgrd$ratioag[ as.numeric(names(ratioag)) ] <- ratioag
@

Here we define a model with an intercept term and a random effect of the
Mat\'ern class. Note how we have fixed, for convenience, 
the value of the range and precision.

<<keep.source=TRUE>>=
formula <-  ratioag ~ 1 + f(spgrd$IDX, model = "matern2d", 
   nrow = nrow, ncol = ncol,
   hyper = list(range = list(initial = log(sqrt(8)/.5), fixed = TRUE),
            prec = list(initial = log(1), fixed = TRUE)))
                

rglinlala <- inla(formula, family = "poisson",
   control.predictor = list(compute = TRUE),
   control.compute = list(dic = TRUE),
   data = as.data.frame(spgrd) )

spgrd$INLALA <- rglinlala$summary.fitted.values[,1]
@

Figure~\ref{fig:geos} shows the observed and estimated radionuclide
concentration in Rongelap island. It can be seen how our model has spatially
smoothed the observed values.

\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE, width=8, height=4>>=
print(spplot(spgrd, c("ratioag", "INLALA"),
   at=seq(0, 12, length.out=10),
   col.regions=gray.colors(10, 0.9, 0.4),
   names.attr=c("DATA", "INLA"),
   par.strip.text=list(cex=1)
))

@
\caption{Observed (left) and estimated (right) radionuclide concentration
in Rongelap island.}
\label{fig:geos}
\end{center}
\end{figure}



\section[Extending {R-INLA} to fit new models]{Extending \pkg{R-INLA} to fit new models} 

\label{sec:extINLA}


Although the current implementation of INLA in the \pkg{R-INLA} package
provides a reasonable number of models for spatial dependence it may be the
case that we need to include some other models. As it is now, this is not
possible.

\citet{Bivandetal:2013} describe a simple way of extending INLA to use other
latent models.  In particular they focus on some latent models used in spatial
econometrics and which are not available as part of the \pkg{R-INLA} package at
the moment.

This approach is based on considering a model where one or several parameters have been
fixed in a way that makes the conditioned model fitable with \pkg{R-INLA}.  If
we denote by $\rho$ the vector of parameters to fix and by $\hat{\rho}$ a
specific set of fixed parameter values,  the full posterior marginal could be
written as


\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \hat{\rho}) 
\end{equation}
\noindent
Taking this into account,  it is clear that when conditioning on
$\rho=\hat\rho$ \pkg{R-INLA} will give us an approximation to
$\pi(x_i|\mathbf{y}, \hat{\rho})$ and $\pi(\theta_i|\mathbf{y}, \hat{\rho})$.



Note that the full posterior distribution can be obtained by integrating $\rho$
out, i.e.,

\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}) = 
\int \pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \rho)\pi(\rho|\mathbf{y})d\rho
\label{eq:fullpost}
\end{equation}
\noindent
where $\pi(\rho|\mathbf{y})$ is the posterior distribution of $\rho$. Also,
note that this can be written as

\begin{equation}
\pi(\rho|\mathbf{y}) \propto \pi(\mathbf{y}|\rho) \pi(\rho)
\label{eq:postrho}
\end{equation}
\noindent
Here $\pi(\rho)$ is a prior distribution on $\rho$ and $\pi(\mathbf{y}|\rho)$
is the marginal likelihood of the model, which is reported by \pkg{R-INLA}.
Hence, $\pi(\rho|\mathbf{y})$ can be estimated by re-scaling
expression in Equation~\ref{eq:postrho}.


The posterior distribution of $\rho$ can be estimated by defining a fine grid
of values $S=\{\rho_i\}_{i=1}^r$ so that $\pi(\rho_i|\mathbf{y}),\ i=\ldots,r$
are computed.  Then $\pi(\rho|\mathbf{y})$ can be obtained by fitting and
re-scaling a spline (or other non-linear function) to the previous values.
Using simple numerical integration techniques we can obtain an approximation to
$\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y})$ as follows:

\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}) = \int \pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \rho)\pi(\rho|\mathbf{y})d\rho
\simeq
\sum_{\rho_i\in S}\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \rho_i)  
\pi(\rho_i|\mathbf{y}) \Delta_i
\label{eq:fullpostapp}
\end{equation}
\noindent
where $\Delta_i$ is the amplitude of the interval used in the discretisation
of $\rho$.

Note that the previous expression can be regarded as a weighted average
of the different models fitted after conditioning on different values of
$\rho$.

From Equation~\ref{eq:fullpostapp} it is clear that we can obtain the following
approximations to the posterior marginals of the individual latent parameters
and hyperparameters:

\begin{equation}
\hat{\pi}(x_i|\mathbf{y}) = \sum_j \pi(x_i|\mathbf{y}, \rho_j) w_j
\end{equation}

\begin{equation}
\hat{\pi}(\theta_i|\mathbf{y}) = \sum_j \pi(\theta_i|\mathbf{y}, \rho_j) w_j
\end{equation}
\noindent
$w_j$ is a weight associated with $\rho_j$ as follows:

\begin{equation}
w_j = \pi(\rho_j|\mathbf{y})\Delta_j
\end{equation}


This is like making a Bayesian Model Averaging \citep{Hoetingetal:1999} on the
different conditioned models fitted with \pkg{R-INLA}. Altogether, this
provides a way of combining simpler models to obtain our desired model. In
Section~\ref{sec:examples} we show how to apply these ideas to different models
in spatial statistics.


%If $\rho$ is a discrete parameter with values in a (finite) set $S$, this can 
%be done by
%
%$$
%\pi(\rho|\mathbf{y}) = \frac{\pi(\mathbf{y}|\rho) \pi(\rho)}{\sum_{\rho_i\in S} \pi(\mathbf{y}|\rho_i) \pi(\rho_i) }
%$$

Note that this approach can be easily extended to the case of $\rho$ being
a discrete random variable.


\subsection{Implementation}

We have implemented this approach in an \pkg{R} package called \pkg{INLABMA},
available from \url{http://r-forge.r-project.org}. The package includes some
general functions to conduct Bayesian Model Averaging of models fitted with
INLA. In addition, we have included some wrapper functions to fit the models
described in Section~\ref{sec:examples}.


\section{Examples}
\label{sec:examples}

\subsection{Leroux model}

\citet{Lerouxetal:1999} propose a model for the analysis of spatial data in a
lattice which is similar to the one by \citet{besagetal:1991}, in the sense
that they split variation according to  spatial and non-spatial patterns.
Rather than including the spatial and non-spatial random effect as a sum in the
linear term they consider a single random effects as follows:

\begin{equation}
u \sim MVN(0, \Sigma);\ \Sigma=\sigma^2 ((1-\lambda) I_n+\lambda M)^{-1}
\label{eq:leroux}
\end{equation}
\noindent
Here $M$ is the precision matrix of a process with spatial structure and we
will take that of an intrinsic CAR specification. Hence, the precision matrix
is, in a sense, a mixture of the precisions of a non-spatial and a spatial
one. $\lambda$ controls how strong the spatial structure is. For $\lambda=1$
the effect is entirely spatial whilst for $\lambda=0$ there is no spatial
dependence.

In principle, this is not a model that \pkg{R-INLA} can fit. However, if
$\lambda$ is fixed, then the random effects are Gaussian with a known structure
for the variance-covariance matrix which can be fitted using a \code{generic0}
latent model.

\subsubsection{Boston housing data}

Here we revisit the Boston housing data to fit the Leroux et al. model.  First
of all, it is worth mentioning that the model needs a wrapper function to be
fitted for a given value of the spatial parameter $\lambda$. This wrapper
function is included in the \proglang{R} package \pkg{R-INLA} and it is based
on the \code{generic0} latent model available in  \pkg{R-INLA}.  Once $\lambda$
is fixed the model can be easily fitted with \pkg{R-INLA}, as the latent effect
is a multivariate Gaussian random effect with zero mean and precision matrix as
in Equation~\ref{eq:leroux}.  We repeat this procedure for different values of
$\lambda$ to obtain a list of fitted models to be combined later.

Hence, we can write a similar wrapper function as in the previous example for
the spatial econometrics models, which is included in package \pkg{INLABMA}:

<<>>=
library("INLABMA")
leroux.inla
@


In the previous code, the precision matrix \code{Q} is created using the adjacency
matrix and the value of $\lambda$. Then the \code{generic0} model is added to the
formula with the fixed effects. Finally we correct the marginal log-likelihood
$\pi(\mathbf{y|\lambda})$ (conditioned on the value of $\lambda$) by adding half the log-determinant of $(1-\lambda)I_n+\lambda M)$.
Note that, in principle, this is not needed to fit a single model and obtain
the approximations to the posterior marginals as it is a constant. However, we
are fitting and combining several models so we need to correct for this
because this scaling factor will change with the value of $\lambda$.
Argument \code{'...'} is used to pass any other options to \code{inla()}. 
This can be used to tune and set a number of other options.

Similar wrapper functions can be written for other models. The functions
included in package \pkg{INLABMA} are similar, but include further options
\citep[see,][for details]{Bivandetal:2013}.

%Note that here \code{zero.variance} is used to set
%to zero the additional error term which is added by default by \pkg{R-INLA}.

<<echo=FALSE, eval=FALSE, keep.source=FALSE>>=
#Zero-variance of error term
zero.variance = list(prec=list(initial = 25, fixed = TRUE))
@

Also, the adjacency matrix is taken from the data provided in the \code{boston}
data set.
Note that we will be using a binary adjacency matrix as the random
effects have an intrinsic CAR specification:
<<keep.source=FALSE>>=
#Binary adjacency matrix
boston.matB <- listw2mat( nb2listw(boston.soi, style = "B") )
bmspB <- as(boston.matB, "CsparseMatrix")
@

Function \code{inla.leroux} is used in the example below to compute the fitted
models for the Leroux et al. model.  In this case, we take $\lambda$ to be in
the interval $(0.8,0.99)$ after previous assessment on where
$\pi(\lambda|\mathbf{y})$ has its mode. Also, we define a prior for the
precision of the random effects in variable \code{fhyper}.  In addition, we
have used \code{mclapply} to parallelise the computations. Note that this is an
advantage of fitting this conditioned models compared standard MCMC methods.

<<keep.source=TRUE>>=
rlambda <- seq(0.8, 0.99, length.out = 15)

fhyper = list(prec = list(prior = "loggamma", 
   param = c(1,1), initial = log(1), fixed = FALSE))

form2 <- log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2) + 
    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)
@

<<leroux, eval=FALSE>>=
lerouxmodels = mclapply(rlambda,
        function(lambda) {
                leroux.inla(form2, d = boston.c, W = boston.matB, 
			lambda = lambda,
                        fhyper = fhyper, improve=TRUE,
                        family = "gaussian",
                        control.predictor = list(compute = TRUE),
                        control.compute = list(dic = TRUE, cpo = TRUE),
                        control.inla = list(print.joint.hyper = TRUE)
                )
        })
@

<<echo=FALSE, eval=FALSE>>=
#Uniform prior on the variances
loginvunif <- "expression:
  precision = exp(log_precision);
  logdens = (precision>1/1000?1:0);
  return(logdens);"


#  logdens=((precision>1000)?(-log(1000)-2*log(precision)):0);
fhyper2 <- list(prec=list(prior=loginvunif))

leroux.inla(form2, d = boston.c, W = boston.matB, lambda = lambda,
                        fhyper = fhyper2, improve = TRUE,
                        family = "gaussian",
#   control.family = list(hyper = zero.variance),
                        control.predictor = list(compute = TRUE),
                        control.compute = list(dic = TRUE, cpo = TRUE),
                        control.inla = list(print.joint.hyper = TRUE)
                )

@



<<echo=FALSE>>=
if(runmodels)
{
<<leroux>>
save(file="lerouxmodels.RData", list=c("lerouxmodels"))
}else{
	#Jpg extension used because of a server side restriction 
	if(!file.exists("lerouxmodels.RData"))
	download.file("http://www.uclm.es/profesorado/vgomez/JSSpaper/lerouxmodels.jpg", "lerouxmodels.RData")

	load("lerouxmodels.RData")
}
@


Following this, we need to combine the different models to obtain the final
model by Bayesian Model Averaging. We will take a uniform prior on $\rho$ and
set the third argument in the following function to $log(1)=0$. Note that
another prior can be used here by giving the log-density of the prior at the
different values of $\rho$.



<<>>=
bmaleroux <- BMA2(lerouxmodels, rlambda, 0, impacts=FALSE)
@
<<echo=FALSE, eval=FALSE>>=
#Using the same prior as in R-INLA:logit(beta) ~ Normal
xxxprec <- .01
xxx <- data.frame(x=seq(-4/sqrt(xxxprec),4/sqrt(xxxprec), length.out=100))
xxx$y <- dnorm(xxx$x, 0, sd=sqrt(1/xxxprec))

xxx2 <- inla.tmarginal(function(x){exp(x)/(1+exp(x))}, xxx)

@


\noindent
\code{bmaleroux} is similar to the object returned by \code{inla()} and it
includes the posterior marginals and summary statistics for $\lambda$
in a list element named \code{rho}. This provides summary statistics (mean,
standard deviation and some quantiles) and the posterior marginal.

The same model can be fitted using package \pkg{CARBayes} \citep{CARBayes:2013}
as follows:

<<keep.source=FALSE>>=
#Run with CARBAYES
library("CARBayes")

#New model
#form2 <- log(CMEDV) ~CRIM+ZN + INDUS + CHAS + I(NOX^2)+
#   I(RM^2) +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)

@
<<carbayes, eval=FALSE>>=
attach(boston.c)
lcarbayes <-  gaussian.lerouxCAR (form2, W = as.matrix(bmspB), 
   burnin = 500,  n.sample = 2500, thin = 5)
detach(boston.c)
@
<<echo=FALSE>>=
if(runmodels){
<<carbayes>>
save(file="lcarbayes.RData", list=c("lcarbayes"))
} else{
	#Jpg extension used becuase of a server side restriction 
	if(!file.exists("lcarbayes.RData"))
		download.file("http://www.uclm.es/profesorado/vgomez/JSSpaper/lcarbayes.jpg", "lcarbayes.RData")

	load("lcarbayes.RData")
}
@

<<eval=FALSE, echo=FALSE>>=
#
#COMMENT: Note that by including an error term and the random effects
#there is a very high negative autocorrelation between the variance
#Probably the error term is redundant and it can be removed
#Also, this may cause some identifiability problem in the variances.
#

 plot(as.vector(lcarbayes$samples.tau2[,1]), as.vector(lcarbayes$samples.nu2[,1]))


@

Table~\ref{tab:leroux} shows point estimates and standard deviations of the
fixed effects and parameter $\lambda$ (bottom line) in the model. It is clear
that there are no significant differences between the estimates computed with
MCMC and our method.  Furthermore, Figure~\ref{fig:leroux} shows the marginal
distribution of $\lambda$ and it shows how our estimate is very close to that
provided by MCMC. The slight difference that is observed may well be due to the
fact that different priors have been used for the variances of the random
effects and the error term. \pkg{CARBayes} uses uniform priors on the variances,
whiles \pkg{R-INLA} assigns inverted Gamma distributions to the variances.

Figure~\ref{fig:leroux} also shows a good agreement between the posterior
means of the fitted values. However, we have found that our estimates
of the posterior marginals of the precisions differ from those obtained
with MCMC. This may be due to the high correlation between these two parameters
(-0.9, computed using the MCMC samples) which may cause some confunding in the
model.

<<echo=FALSE, results=tex>>=
library("xtable")

tab <- cbind(bmaleroux$summary.fixed[, 1:2], summary(lcarbayes$samples.beta)[[1]][,1:2])
tab <- rbind(tab, c(bmaleroux$rho$mean, bmaleroux$rho$sd, 
   1-summary(lcarbayes$samples.rho)[[1]][1], 
   summary(lcarbayes$samples.rho)[[1]][2])
)
rownames(tab)[nrow(tab)] <- "lambda"

colnames(tab) <- c("Mean (INLA)", "SD (INLA)", "Mean (MCMC)", "SD (MCMC)") 


xtab <- xtable(tab, digits=4)
xtab[nrow(xtab), 3] <-  1- xtab[nrow(xtab), 3] #CARBAyes gives 1-lambda
caption(xtab) <- "Point estimates of fixed effects and $\\lambda$ using INLA and MCMC."
label(xtab) <- "tab:leroux"

print(xtab)
@


\begin{figure}[h]
\begin{center}
<<echo=FALSE, fig=TRUE>>=
par(mfrow=c(2,2))
#Compare results between INLA and CARBayes
plot(density(lcarbayes$samples.rho, from=0, to=1), xlim=c(0.8,1),
  main=expression(paste("Marginal distribution of ", lambda)))
lines(bmaleroux$rho$marginal[,1], bmaleroux$rho$marginal[,2], col="red")
legend(.15, 15, c("INLA", "MCMC"), col=c("red", "black"), lty=1)

#Precission of error term
plot(density(1/lcarbayes$samples.nu2 ),
  main=expression(paste("Marginal distribution of ", 1/sigma^2, " error")))
lines(bmaleroux$marginals.hyperpar[[1]], col="red")

#Precission of random effects
plot(density(1/lcarbayes$samples.tau2 ),
  main=expression(paste("Marginal distribution of ", 1/sigma^2, " rand. eff.")) )
lines(bmaleroux$marginals.hyperpar[[2]], col="red")

#Fitted values
plot(lcarbayes$fitted.values[,1], bmaleroux$summary.fitted.values[,1],
   main="Fitted values (posterior mean)", xlab="MCMC", ylab="INLA")
abline(0,1)

@
\end{center}
\caption{Comparisson between the posterior marginals of several parameters in 
Leroux et al.'s model and fitted values with INLA (red) and MCMC (black).}
\label{fig:leroux}
\end{figure}

While writting this paper, \citet{LeeMitchell:2013} have come up with an
alternative way of fitting this model using \pkg{R-INLA} and a \code{generic1}
latent model. In general, the results obtained for $\lambda$ with our approach
are very similar to the ones obtained with theirs for the Boston housing data.


<<echo=FALSE, eval=FALSE>>=
#As suggested by Lola Ugarte

#My matrix: (1-lambda)*I_n+lambda*CAR
Q  <-  diag(1-apply(boston.matB, 1, sum)) + boston.matB

#Lola's code
form3 <- log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2) +
    AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)+
    f(idx, model="generic1",  Cmatrix = Q, constr=TRUE, 
    hyper =list(prec=list(prior="loggamma", param=c(1,5e-5)),
    beta=list(prior="gaussian", param=c(0,.01)))
)

leroux2 <- inla(form3,  data=boston.c, family = "gaussian",
#    control.family = list(hyper = zero.variance),
     control.predictor=list(compute=TRUE),
                        control.compute=list(dic=TRUE, cpo=TRUE),
                        control.inla=list(print.joint.hyper=TRUE)
                )


#Compare results between INLA and CARBayes
plot(density(lcarbayes$samples.rho, from=0, to=1), xlim=c(0.8,0.99),
  main=expression(paste("Marginal distribution of ", lambda)))
lines(bmaleroux$rho$marginal[,1], bmaleroux$rho$marginal[,2], col="red")
lines(leroux2$marginals.hyperpar[[3]], col="blue")
legend(.15, 15, c("INLA", "MCMC"), col=c("red", "black"), lty=1)

kk <- inla.tmarginal(function(x){1-x}, leroux2$marginals.hyperpar[[2]])
lines(kk,  col="blue")

kkk <- inla.tmarginal(function(x){x/10.3}, leroux2$marginals.hyperpar[[2]])
lines(kkk, col="pink")



@






\subsection{Spatial econometrics models}

\citet{LeSagePace:2009} describe a good deal of models amply used in spatial
econometrics. These models have been developed to make it explicit that there
is dependence among the observed values $y_i$. First of all, spatial dependence
can be assumed on the error term, so that we have a slightly different model:

\begin{equation}
y= \alpha+\beta X +u; u=\rho W u+\varepsilon
\end{equation}
\noindent
Here the error term $u$ is assumed to have spatial dependence.  $\rho$ is a
parameter that controls spatial autocorrelation, $\alpha$ is the intercept, $X$
a design matrix of covariates and $\beta$ a vector of associated coefficients.
$\varepsilon$ is an error term which is Gaussian with zero mean and
variance-covariance matrix $\Sigma$. Here, $\Sigma = \sigma^2 I_n$ with $I_n$
being a $n\times n$ identity matrix and $\sigma^2$ is the variance of the error
term.


The adjacency matrix $W$ is often taken to be row-standardised \citep[see, for
example,][]{Haining:2003} to ensure that $\rho$ in the interval $(-1, 1)$.
Also, when $\rho$ is equal to zero there is no spatial dependence.

This can be reformulated as

\begin{equation}
y= \alpha+\beta X+\varepsilon'
\end{equation}
\noindent
$\varepsilon '$ is now an error term with a Gaussian distribution with zero
mean and variance-covariance matrix $\Sigma=((I_n-\rho W)(I_n-\rho W'))^{-1}$.
Note that this variance-covariance encodes spatial dependence in a particular
way and that this is often referred to as Spatial Autoregressive (SAR)
specification.


Alternatively, autocorrelation can be modelled explicitly so that the
variable response $y$ depends on itself as follows:

\begin{equation}
y= \alpha+\beta X+\rho W y +\varepsilon 
\end{equation}
\noindent
This model can be reformulated as

\begin{equation}
y = (I_n-\rho W)^{-1}(\alpha+\beta X)+\varepsilon ' 
\label{eq:slm}
\end{equation}
\noindent
where $\varepsilon '$ is a Gaussian term with zero mean and
variance-covariance matrix with a SAR specification.

In addition to the previous models, sometimes lagged covariates are 
added to include the effects of neighbouring covariates. This is known
as Spatial Durbin Model  and it is often expressed as

\begin{equation}
y= \rho W y+ \alpha+\beta X+\gamma W X +\varepsilon 
\end{equation}
\noindent
which leads to

\begin{equation}
y= (I_n-\rho W)^{-1}(\alpha+\beta X+\gamma W X) +\varepsilon '
\end{equation}
\noindent
Note that this is like our previous model in Equation~\ref{eq:slm} using an extended
design matrix that includes both $X$ and $W X$.

These models cannot be fitted with \pkg{R-INLA} for two reasons. First of all, 
the SAR specification is not implemented, so we cannot consider it for out
error terms. Furthermore, it is not possible to define a model 
where the linear predictor is multiplied by $(I_n-\rho W)^{-1}$.

Following Section~\ref{sec:extINLA}, it should be noted that, for a fixed
$\rho$ these models become standard linear models with a particular 
(but known) design matrix for the fixed effects and a multivariate Gaussian
distribution with zero mean and variance-covariance matrix.

This model can be easily fitted using \pkg{R-INLA} for different values
of $\rho$. Note that, according to \citet{Haining:2003}, $\rho$ is constrained 
to be in the interval $(1/\lambda_{min}, 1/\lambda_{max})$, with
$\lambda_{min}$ and $\lambda_{max}$ the minimum and maximum eigenvalues of
the adjacency matrix $W$. For row standardised adjacency matrices we have that
$\lambda_{max}=1$ and then $\rho$ is lower than 1. Furthermore, we are often
interested in positive spatial autocorrelation and, in practice, we will
assume that $\rho$ is in the interval $[0,1)$.


Finally, we have considered here the Gaussian case, but it is very easy to
extend this model to consider other likelihoods. In particular,
\citet{LeSageetal:2011} describe a Spatial Probit model where the outcome is
whether an event occurred. Hence, the response and the linear predictors are
linked via a probit function as follows:

\begin{equation}
y_i=
\left\{
\begin{array}{cc}
1 & if y^*_i\geq 0\\
0 & if y^*_i < 0
\end{array}
\right.
\end{equation}

The previous approach can be used here as well. The same code will still work
as we can define a different family and link function to be used when calling
\code{inla()}.

\subsubsection{Boston housing data}

Here we revisit the Boston housing data to fit the three models on Spatial
Econometrics previously described. First of all, it is worth mentioning that
each models needs a wrapper function to be fitted for a given value of the
spatial autocorrelation parameter $\rho$. These wrapper functions are included
in \proglang{R} package \pkg{R-INLA}.

All functions are based on the \code{generic0} model available in  \pkg{R-INLA}.
This model implements a multivariate Gaussian random effect with zero mean
and precision matrix $\tau Q$. Once $\rho$ is fixed, $Q$ is
known and the model can be easily fitted with \pkg{R-INLA} for that value of
$\rho$. We repeat this procedure for different values of $\rho$ to
obtain a list of fitted models to be combined later.

A simple wrapper function can be defined as follows for the SEM model:

<<keep.source=FALSE>>=
semwr.inla <- function(formula, d, W, rho,...)
{
        IrhoW <- diag(nrow(W)) - rho*W
        IrhoW2 <- IrhoW %*% t(IrhoW)

        environment(formula) <- environment()

        formula <- update(formula,
          . ~ . + f(idx, model = "generic0", Cmatrix = IrhoW2) )

        res <- inla(formula, data=d, ...)

  #Compute log-determinat to correct the marginal-loglikelihood
        res$logdet <- as.numeric( determinant(IrhoW2)$modulus )
        res$mlik <- res$mlik+res$logdet / 2

        return(res)
}
@

In the previous code, the precision matrix \code{IrhoW2} is created using the
adjacency matrix and the value of $\rho$ and the \code{generic0} model is added
to the formula after the fixed effects. As discussed with the Leroux model, the
marginal log-likelihood $\pi(\mathbf{y|\rho})$  (note that now we are
conditioning on $\rho$) is corrected by adding half the log-determinat of
$(I_n-\rho W')(I_n-\rho W)$.  Argument \code{'...'} is used to pass any other
options to \code{inla()}.

Similar wrapper functions can be written for the other models. The functions
included in package \pkg{INLABMA} are similar, but include further options,
to improve fitting or compute the impacts 
\citep[see,][for details]{Bivandetal:2013}.

This is used in the following example to compute the fitted models
for the SEM model. Note that here \code{zero.variance} is used to set
to zero the additional error term which is added by default by \pkg{R-INLA}.
Also, the adjacency matrix is taken from the data provided in the \code{boston}
data set.

<<keep.source=FALSE>>=
#Zero-variance of error term
zero.variance = list(prec=list(initial = 25, fixed=TRUE))


#INLA: SAR model

#Adjacency matrix
boston.mat <- nb2mat(boston.soi)
bmsp <- as(boston.mat, "CsparseMatrix")

#index for sptial effect
boston.c$idx <- 1 : nrow(boston.c)

@

Next, we define a fine grid on the interval $(0,1)$ to give values
to $\rho$ and compute the different models under these values. Again,
we have used \code{mclapply}  to speed up computations.


<<>>=
fform <- log(CMEDV) ~CRIM+ZN + INDUS + CHAS + I(NOX^2)+
   I(RM^2) +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)

rrho1 <- seq(0.5, 0.9, len = 20)
@
<<semmodels, eval=FALSE>>=
semmodels = mclapply(rrho1,
        function(rho) {
                sem.inla(fform, d = boston.c, W = boston.mat, rho = rho,
                        family = "gaussian", impacts = FALSE,
                        control.family = list(hyper = zero.variance),
                        control.predictor = list(compute = TRUE),
                        control.compute = list(dic = TRUE, cpo = TRUE),
                        control.inla = list(print.joint.hyper = TRUE)
                )
        })
@
<<echo=FALSE>>=
if(runmodels){
<<semmodels>>
save(file="semmodels.RData", list=c("semmodels"))
} else {
	#Jpg extension used becuase of a server side restriction 
	if(!file.exists("semmodels.RData"))
		download.file("http://www.uclm.es/profesorado/vgomez/JSSpaper/semmodels.jpg", "semmodels.RData")

	load("semmodels.RData")
}
@

\noindent
Following this, we need to combine the different models
to obtain the final model by Bayesian Model Averaging. As in the
example on the Leroux model, we will take
a uniform prior on $\rho$ and set the third argument in the following
function to $\log(1)=0$. 

<<>>=
bmasem <- BMA2(semmodels, rrho1, 0 , impacts = FALSE)
@

\code{bmasem} is similar to the object returned by \code{inla()} and it
includes the posterior marginals and summary statistics for $\rho$.

SLM and SDM models can be fitted using similar code. In the case of
the SLM, first we compute the design matrix (of the fixed effects) 
to be used later when fitting the models. This will speed up the 
computations.

<<>>=
mmatrix <- model.matrix(fform, boston.c)

rrho2 <- seq(0.3, 0.6, len = 20)
@

<<slmmodels, eval=FALSE>>=
slmmodels = mclapply(rrho2,
        function(rho) {
                slm.inla(form, d = boston.c, W = boston.mat, rho = rho, 
			mmatrix = mmatrix,
                        family = "gaussian", impacts = TRUE,
                        control.family = list(hyper = zero.variance),
                        control.predictor = list(compute = TRUE),
                        control.compute = list(dic = TRUE, cpo = TRUE),
                        control.inla = list(print.joint.hyper = TRUE)
                )
        })

@
<<echo=FALSE>>=
if(runmodels){
<<slmmodels>>
save(file="slmmodels.RData", list=c("slmmodels"))
} else {
	#Jpg extension used becuase of a server side restriction 
	if(!file.exists("slmmodels.RData"))
		download.file("http://www.uclm.es/profesorado/vgomez/JSSpaper/slmmodels.jpg", "slmmodels.RData")

	load("slmmodels.RData")
}
@

<<>>=
bmaslm <- BMA2(slmmodels, rrho2, 0 , impacts = FALSE)
@

In the case of the SDM, it is very helpful to compute $X$ and $WX$ beforehand
to reduce computation time, as this is common to all the fitted models
regarless of the value of $\rho$. This can be later passed to wrapper function
\code{sdm.inla}.

<<>>=
mmW <- bmsp %*% mmatrix[,-1]#Remove intercept
mmatrixsdm <- cbind(mmatrix, as.matrix(mmW) )

rrho3 <- seq(0.4, 0.7, len = 20)
@

<<sdmmodels, eval=FALSE, keep.source=TRUE>>=
sdmmodels = mclapply(rrho3,
        function(rho) {
                sdm.inla(form, d = boston.c, W = boston.mat, rho = rho, 
			mmatrix = mmatrixsdm,
                        family = "gaussian", impacts = TRUE,
                        control.family = list(hyper = zero.variance),
                        control.predictor = list(compute = TRUE),
                        control.compute = list(dic = TRUE, cpo = TRUE),
                        control.inla = list(print.joint.hyper = TRUE)
                )
        })
@
<<echo=FALSE>>=
if(runmodels){
<<sdmmodels>>
save(file="sdmmodels.RData", list=c("sdmmodels"))
} else{
	#Jpg extension used becuase of a server side restriction 
	if(!file.exists("sdmmodels.RData"))
		download.file("http://www.uclm.es/profesorado/vgomez/JSSpaper/sdmmodels.jpg", "sdmmodels.RData")

	load("sdmmodels.RData")
}
@

<<>>=
bmasdm <- BMA2(sdmmodels, rrho3, 0 , impacts = FALSE)
@

As we have seen in the previous examples, combining the different values 
for the different values of $\rho$ provides accurate estimates of the posterior
marginals for the model parameters. The estimates of the marginals of
$\rho$ can be found in Figure~\ref{fig:pmargrho}.

\begin{figure}[h]
\begin{center}
<<eval=TRUE, echo=FALSE, fig=TRUE, width=8, height=4>>=
plot(bmasem$rho$marginal, xlab=expression(rho), 
   ylab=expression(paste(pi, "(", rho, "|y)")),
   main="", type="l", xlim=c(0,1), ylim=c(0, 15))
lines(bmaslm$rho$marginal, lty=2)
lines(bmasdm$rho$marginal,lty=3)

legend(0, 15, legend=c("SEM", "SLM", "SDM"), lty=1:3)

@
\end{center}
\caption{Posterior marginal of the spatial autocorrelation parameter $\rho$
for different spatial econometrics models, Boston housing data.}
\label{fig:pmargrho}
\end{figure} 



%\subsection{Model Selection with INLA and RJMCMC}

%\subsubsection{Boston Housing Data}

%\subsection{Spatio-temporal models}
%
%Spatio-temporal models can be easily fitted with \pkg{R-INLA} when the spatial
%and temporal effects are separable. However, it may be a complex issue when 
%
%\subsubsection{Cancer in New Mexico}



\section{Discussion} \label{sec:disc}

The Integrated Nested Laplace Approximation has provided a new paradigm to
model fitting in Bayesian analysis. By focusing on the marginals and providing
an interesting computational approach, it has provided a reasonable and faster
alternative to MCMC. Furthermore, the \pkg{R-INLA} package makes model fitting
in \proglang{R} a very simple task.  Although \pkg{R-INLA} implements some key
models, there are some others that have not been implemented yet.
In addition, it is not easy to implement completely new models within the
\pkg{R-INLA}.

In this paper we have shown an innovative approach to model fitting with INLA
and \pkg{R-INLA} which increases the number of latent models that can be fitted
with INLA. We have been able to do so by fitting conditional models on some
model parameters and combining the resulting models using simple methods for
Bayesian model averaging. We have considered the case in which conditioning is
carried out on a single parameter but our approach can be easily extended to the
case of more than one parameter.

Given that the different models can be run in parallel, this is not a real
computational burden. In our examples, 20 models seemed to be enough to obtain
good approximations. Implementing new models is very simple and the wrapper
functions included in the examples and the \pkg{INLABMA} package provide
templates to start with.

Other computationally efficient approaches for Bayesian inference on spatial 
models include, for example, \pkg{RStan} \citep{stan-software:2013}.
It provides an efficient MCMC algorithm and provides a good number of options
for Gaussian processes which can be used to implement some of the models
described in this paper. It is worth mentioning that \pkg{RStan} models are not
based on \pkg{R} code but on \pkg{C++} code that is compiled once the main
model is defined.

We have shown that this is a practical approach using different examples in
spatial statistics. Similarly, complex spatio-temporal models could be fitted
using a similar approach. However, it should be noted that our approach can be
extended to other areas.

\section*{Acknowledgements}

We would like to thank Duncan Lee and Lola Ugarte for their help and comments
on how to fit the Leroux model with \pkg{R-INLA}.


%\bibliography{INLA_econometrics,RS_handbook_SpatStat_INLA,JSSpaper}
\bibliography{biblio.bib}


\end{document}
