%Sweave("spatial_inla.Rnw", encoding="UTF-8", keep.source=FALSE)
%system("pdflatex spatial_inla.tex")
%system("bibtex spatial_inla")
\documentclass[article]{jss}

\usepackage{thumbpdf}
\usepackage{amssymb}
%% need no \usepackage{Sweave.sty}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Roger S. Bivand\\NHH Norwegian\\ School of Economics \And 
Virgilio G\'omez-Rubio\\Universidad de\\ Castilla-La Mancha 
\And H\r{a}vard Rue\\Norwegian University for\\ Science and Technology
%Achim Zeileis\\Universit\"at Innsbruck \And 
%        Second Author\\Plus Affiliation}
}
%\title{Extending the \pkg{R-INLA} Package for Spatial Statistics}
%\title{Some Spatial Statistical Extensions to \pkg{R-INLA}}
\title{Spatial Data Analysis with \pkg{R-INLA} with Some Extensions}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Roger S. Bivand, Virgilio G\'omez-Rubio, H\r{a}vard Rue}
\Plaintitle{Some Spatial Statistical Extensions to R-INLA}
%\Shorttitle{} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The integrated nested Laplace approximation (INLA) provides an interesting
way of approximating the posterior marginals of a wide range of Bayesian
hierarchical models. This approximation is based on conducting a 
Laplace approximation of certain functions and numerical integration is
extensively used to integrate some of the models parameters out. 

The \pkg{R-INLA} package offers an interface to INLA, providing a suitable
framework for data analysis. Although the INLA methodology can deal with
a large number of models, only the most relevant have been implemented
within \pkg{R-INLA}. However, many other important models are not available
for \pkg{R-INLA} yet.

In this paper we show how to fit a number of spatial models with \pkg{R-INLA},
including its interaction with other \proglang{R} packages for data analysis.
Secondly, we describe a novel method to extend the number of latent models
available for the model parameters. Our approach is based on conditioning on
one or several model parameters and fit these conditioned models with
\pkg{R-INLA}.  Then these models are combined using Bayesian model averaging
(BMA) to provide the final approximations to the posterior marginals of the
model.

Finally, we show some examples of the application of this technique
in spatial statistics. It is worth noting that our approach can be extended
to a number of other fields, and not only spatial statistics.


}
\Keywords{INLA, spatial statistics, \proglang{R}}
\Plainkeywords{INLA, spatial statistics, R}
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
Roger S. Bivand\\
Department of Economics\\
NHH Norwegian School of Economics\\
Helleveien 30\\
N-5045 Bergen, Norway\\
 \\
%}
%\Address{
Virgilio G\'omez-Rubio\\
Department of Mathematics\\
School of Industrial Engineering\\
University of Castilla-La Mancha\\
02071 Albacete, Spain\\
 \\
%}
%\Address{
H\r{a}vard Rue\\
Department of Mathematical Sciences\\
Norwegian University for Science and Technology\\
N-7491 Trondheim, Norway
}

\begin{document}

\section[Introduction]{Introduction}


Bayesian inference has become very popular in spatial statistics in recent
years. Part of this success is due to the availability of computation methods
to tackle fitting of spatial models. \citet{besagetal:1991} proposed in their
seminal paper an appropriate way of fitting a spatial model using Markov chain
Monte Carlo methods. This model has been extensively used and extended to
consider different types of fixed and random effects for spatial and
spatio-temporal analysis.

In general, fitting these models has been possible because of the availability
of different computational techniques, the most notable being Markov Chain
Monte Carlo (MCMC). For large models or big data sets, MCMC can be tedious and
reaching the required number of samples can take a long time. Not to mention
that autocorrelation may arise and that an increased number of iterations may
be required.

Alternatively, the posterior distributions of the parameters may be
approximated in some way. However, most models are highly multivariate and
approximating the full posterior distribution may not be possible in practice.
The integrated nested Laplace approximation \citep[][INLA]{isi:000264374200002}
focuses on the posterior marginals for latent Gaussian models. Although these
models may seem rather restricted, they appear in a fair number of fields.
This also means that INLA will be particularly useful when only marginal
inference on the model parameters is needed.

The \pkg{R-INLA} package \citep{rinla:2013} for the \proglang{R} programming
language provides an interface to INLA (a free-standing programme) so that models can be fitted using
standard \proglang{R} commands. Results are readily available for plotting or
further analysis. First of all, we describe how \pkg{R-INLA} can be used
together with other \proglang{R} packages for spatial data analysis. It is often
the case that spatial data are available in different formats
that need to be loaded into \proglang{R} and some pre-processing is
required. Also, once the results are available, it is helpful to explain 
how to display them on a map.

Although INLA is a general method to approximate the
posterior marginals, \pkg{R-INLA} implements a number of popular latent models and prior
distributions for the model parameters.
It is, however, difficult to fit new models with INLA if these
are based on other distributions not available in \pkg{R-INLA}.  This may be an
inconvenience when trying to develop new models as there is no easy way of
extending \pkg{R-INLA} to fit other models without writing them into INLA itself.

This is why we also describe a way of extending the number of models that
\pkg{R-INLA} can fit with little extra effort. First of all, we consider one
(or more) parameters in our model so that, if they are fixed, the resulting
model can be fitted with \pkg{R-INLA}. What we are doing here is, in fact, to
fit a model conditioned on the assigned values to the parameters. Then, we can
assign different values to these parameters and combine the resulting models in
some way to obtain a fit of the original model. We have used Bayesian model
averaging and numerical integration techniques to combine these models \citep{Bivandetal:2014}.


This paper is organised as follows. Section~\ref{sec:INLA} describes the
integrated nested Laplace approximation.  In Section~\ref{sec:spmodels} the
different latent models for spatial statistics are described.  We describe how
to extend \pkg{R-INLA} to fit new models in Section~\ref{sec:extINLA}. Some
examples are provided in Section~\ref{sec:examples}.  Finally, we discuss why
our approach is relevant in Section~\ref{sec:disc}.

\section{Integrated nested Laplace approximation}
\label{sec:INLA}

Bayesian inference is based on computing the posterior distribution of a
vector of model parameters $\mathbf{x}$ conditioned on the vector of observed
data $\mathbf{y}$. Bayes' rule states that this posterior distribution
can be written down as

\begin{equation}
\pi(\mathbf{x}|\mathbf{y}) \propto \pi(\mathbf{y}|\mathbf{x}) \pi(\mathbf{x})
\end{equation}
\noindent
Here, $\pi(\mathbf{y}|\mathbf{x})$ is the likelihood of the model and
$\pi(\mathbf{x})$ represents the prior distribution on the model parameters.


Usually, $\pi(\mathbf{x}|\mathbf{y})$ is a highly multivariate distribution
and difficult to obtain. In particular, it is seldom possible to derive it in
a closed form. For this reason, several computational approaches  have been 
proposed to get approximations to it. MCMC is probably the most widely used
family of computational approaches to estimate the posterior distribution.

The marginal distribution of parameter $x_i$ can be denoted by
$\pi(x_i|\mathbf{y})$ and it can be easily derived from the full posterior by
integrating out over the remaining set of parameters $\mathbf{x}_{-i}$.

Let us assume that we have a set of $n$ observations 
$\mathbf{y}=\{y_i\}_ {i=1}^n$, whose distribution is of the exponential family.
The mean of observation $i$ is $\mu_i$ and it can depend on a linear predictor 
$\eta_i$ via a link function. In turn, the linear
predictor $\eta_i$ can be modelled as follows:

\begin{equation}
\eta_i=\alpha+\sum_{j=1}^{n_f} f^{(j)}(u_{ji})+\sum_{k=1}^{n_{\beta}}\beta_k z_{ki}+\varepsilon_i
\end{equation}
\noindent
$\alpha$ is the intercept, $f^{(j)}$ are functions on a set of $n_f$ random
effects on a vector of covariates $\mathbf{u}$, $\beta_k$ are coefficients on
some covariates $\mathbf{z}$ and $\varepsilon_i$ are error terms. Hence, the
vector of latent effects is $\mathbf{x}=\{\{\eta_i\}, \alpha, \{\beta_k\},
\ldots\}$. Note that given our particular interest in spatial models, terms
$f^{(j)}(u_{ji})$ can be defined as to model spatial or spatio-temporal
dependence.

$\mathbf{x}$ is modelled using a Gaussian distribution with zero mean and
variance-covariance matrix $Q(\theta_1)$. Now, $\theta_1$ is a vector of
hyperparameters. Furthermore, $\mathbf{x}$ is assumed to be a Gaussian Markov
random field \citep[GMRF,][]{rueheld:2005}. This means that  $Q(\theta_1)$ will fulfil a number of
Markov properties. 
%This will make $y_i$ independent given $x_i$ and $\theta$.

The distribution of observations $y_i$ will depend on the latent effects
$\mathbf{x}$ and, possibly, a number of hyperparameters $\theta_2$.  Taking
the vector of hyperparameters $\theta=(\theta_1, \theta_2)$, observations
$y_i$ will be independent of each other given $x_i$ and $\theta$ because
of $\mathbf{x}$ being a GMRF.

Following \citet{isi:000264374200002}, the posterior distribution of the model
latent effects $\mathbf{x}$ and hyperparameters $\theta$ can be written as 

\begin{eqnarray}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}) \propto
\pi(\mathbf{\theta}) \pi(\mathbf{x}|\mathbf{\theta})\prod_{i\in \mathcal{I}}\pi(y_i|x_i,\mathbf{\theta})
\propto  \\ \nonumber
\pi(\mathbf{\theta}) |\mathbf{Q}(\mathbf{\theta})|^{1/2} \exp\{-\frac{1}{2}\mathbf{x}^T \mathbf{Q}(\mathbf{\theta}) \mathbf{x}+\sum_{i\in\mathcal{I}} \log(\pi(y_i|x_i, \mathbf{\theta})) \}
\end{eqnarray}
\noindent
$\mathcal{I}$ represents an index of observed data (from 1 to $n$),
$\mathbf{Q}(\mathbf{\theta})$ is a precision matrix on some
hyperparameters $\theta$ and $\log(\pi(y_i|x_i, \mathbf{\theta}))$ is
the log-likelihood of observation $y_i$.

INLA allows different forms for the likelihood of the observations.  This
includes not only distributions from the exponential family but also mixtures
of distributions. Also, INLA can handle observations with different likelihoods
in the same model. Regarding the latent effects $\mathbf{x}$, different models
can be used. We will describe some of these in more detail in
Section~\ref{sec:spmodels}.


The specification of the prior distributions $\pi(\theta)$ is also very 
flexible. These will often depend on the latent effect but, in principle,
the most common distributions are available and the user can define their
own prior distribution in the \pkg{R-INLA} package (but we will return
to this later). 

Hence, we can write the marginals of the elements in $\mathbf{x}$
and $\mathbf{\theta}$ (i.e., latent effects and hyper-parameters) as
%FIXME RSB is "the marginal distributions of the elements" the same as "the distributions of the marginals of the elements" which is the expansion of the genetives in "the marginals distributions of the elements" as was written before.
%VIRGILIO: I have changed this to "the marginals of the elements". FIXED.

\begin{equation}
\pi(x_i|\mathbf{y}) = \int \pi(x_i|\mathbf{\theta}, \mathbf{y})  \pi(\mathbf{\theta}| \mathbf{y}) d\mathbf{\theta}
\end{equation}
\noindent
and

\begin{equation}
\pi(\theta_j|\mathbf{y}) = \int \pi(\mathbf{\theta}| \mathbf{y})  d\mathbf{\theta}_{-j} 
\end{equation}

In order to estimate the previous marginals, we need 
$\pi(\mathbf{\theta}|\mathbf{y})$ or, alternatively, a convenient
approximation that we will denote by $\tilde\pi(\theta|\mathbf{y})$.
Initially, this approximation can be taken as

\begin{equation}
\tilde\pi(\mathbf{\theta}|\mathbf{y})\propto 
\frac{\pi(\mathbf{x},\mathbf{\theta},\mathbf{y})}{\tilde\pi_G(\mathbf{x}|\mathbf{\theta},\mathbf{y})}\bigg|_{x=x^*(\theta)}
\end{equation}
\noindent
Here 
$\tilde\pi_G(\mathbf{x}|\mathbf{\theta},\mathbf{y})$ is a Gaussian
approximation to the full conditional of $\mathbf{x}$ and $x^*(\theta)$
is the mode of the full conditional for a given value of $\mathbf{\theta}$.
\citet{isi:000264374200002} take this approximation and use it 
to compute the marginal distribution of $x_i$ using numerical integration:

\begin{equation}
\tilde\pi(x_i|\mathbf{y})= 
\sum_k \tilde\pi (x_i|\mathbf{\theta}_k, \mathbf{y})\times 
\tilde\pi(\mathbf{\theta}_k|\mathbf{y})\times \Delta_k
\end{equation}
\noindent
Here $\Delta_k$ are the weights associated with the ensemble of values
$\mathbf{\theta}_k$, defined on a multidimentional grid over
the space of hyperparameters.

%\citet{isi:000264374200002}  also discuss how the approximation $\tilde\pi
%(x_i|\mathbf{\theta}_k, \mathbf{y})$ should be in order to reduce numerical
%error and they provide different alternatives.

Note that in the previous equation it is important to have good approximations
of $\pi (x_i|\mathbf{\theta}_k, \mathbf{y})$. A Gaussian approximation
$\tilde\pi_G (x_i|\mathbf{\theta}_k, \mathbf{y})$, with mean $\mu_i(\theta)$
and variance $\sigma^2_i(\theta)$, may be a good starting point but a better
approximation may be required in other cases. \citet{isi:000264374200002}
developed better approximations based on alternative approximation methods,
such as the Laplace approximation.  For example, they have used the Laplace
approximation to obtain:

\begin{equation}
\tilde\pi_{LA}(x_i|\mathbf{\theta}, \mathbf{y}) \propto 
\frac{\pi(\mathbf{x}, \mathbf{\theta}, \mathbf{y})}
{\tilde\pi_{GG}(\mathbf{x}_{-i}|x_i, \mathbf{\theta}, \mathbf{y})}
\bigg|_{\mathbf{x}_{-i}=\mathbf{x}^*_{-i}(x_i, \mathbf{\theta})}
\end{equation}
\noindent
$\tilde\pi_{GG}(\mathbf{x}_{-i}|x_i, \mathbf{\theta}, \mathbf{y})$ is a
Gaussian  approximation to $\mathbf{x}_{-i}|x_i, \mathbf{\theta}, \mathbf{y}$
around its mode $\mathbf{x}^*_{-i}(x_i, \mathbf{\theta})$.

\citet{isi:000264374200002} develop a simplified Laplace approximation to
improve $\tilde\pi_{LA}(x_i|\mathbf{\theta}, \mathbf{y})$ using a series
expansion of the Laplace approximation around $x_i$. This approximation is
computationally less expensive, and it also corrects for location and
skewness.


\subsection[The R-INLA package]{The \pkg{R-INLA} package}

An interface to INLA has been provided as an \proglang{R} package called \pkg{R-INLA},
which can be downloaded from \url{http://www.r-inla.org/}, together with the free-standing external INLA programme. \pkg{R-INLA}
provides a user model interface similar to the one used to fit generalised additive
models (GAM) with function \code{gam()} in the \pkg{mgcv} package \citep{Wood:2006}. %FIXME RSB reference? YES, FIXED.
It can handle fixed effects, non-linear terms
and random effects in a \code{formula} argument. The interface is flexible
enough to allow for the specification of different priors and model fitting
options. Non-linear terms and random effects are included in the formula as
calls to the \code{f()} function. 


The model is fitted with a call to function \code{inla()}, which will return the fitted model as an
\code{inla} object. Note that, by default, only some results will be returned. These include the marginal distributions of
the latent effects and hyperparameters, as well as summary statistics. 


In addition to the posterior marginals, \pkg{R-INLA} can provide a number
of additional quantities on the fitted model. For example, it can 
provide the log-marginal likelihood $\pi(\mathbf{y})$ which can be used
for model selection. Other model selection criteria such as the DIC 
\citep{Spiegelhalteretal:2002} and CPO \citep{Heldetal:2010} have also
been implemented.

Furthermore, \pkg{R-INLA} includes a number of options to define the
prior distributions for the parameters in the model. Well-known
prior distributions are available and the user can define their own prior
distributions as well.

In the next Section we describe different examples of the use of
\pkg{R-INLA} for spatial statistics, in which we have included
a detailed description on how \code{inla()} should be called.

\section{Spatial models with INLA} \label{sec:spmodels}


As discussed in Section~\ref{sec:INLA}, spatial dependence can be included as
part of the vector of latent effects $\mathbf{x}$. In principle, any number of
random effects can be included in the model. In this Section, we will describe
the different options available, depending on the type of problem. A full
description of the models described here can be found in the \pkg{R-INLA}
website at \url{http://www.r-inla.org}, but we have included a summary.
\citet{Blangiardoetal:2013} and \citet{GomezRubioetal:2013} also discuss
the different spatial models included in \pkg{R-INLA}.

%{\bf ADD MORE STUFF BELOW}

First we will briefly introduce other papers describing the use of INLA and \pkg{R-INLA} for spatial statistics. \citet{SchrodleHeld:2010} %FIXME RSB umlaut in references? YES, FIXED.
 describe the use of spatial
and spatio-temporal models for disease mapping, including ecological regression.
\citet{SchrodleHeld:2011} expand the number of spatio-temporal models that
can be used with \pkg{R-INLA}, and show the use of setting linear constraints to make complex spatio-temporal effects identifiable. 
\citet{isi:000288017300007} show how to use spatio-temporal models
for disease surveillance. \citet{Eidsviketal:2012} focus on the use
of \pkg{R-INLA} for the analysis of large spatial datasets. Finally, 
\citet{Ruiz-Cardenasetal:2012} develop spatio-temporal dynamic models
with \pkg{R-INLA}.


\subsection{Analysis of lattice data}

First of all, we will discuss the analysis of lattice data because this will
establish the basis for other types of analyses. In the analysis of lattice data
observations are grouped according to a set of areas, which usually represent
some sort of administrative region (neighbourhoods, municipalities, provinces,
countries, etc.).

\pkg{R-INLA} includes a latent model for uncorrelated random effects. In
this case, the random effects $u_i$ are modelled as

\begin{equation}
u_i \sim N(0, \tau_u)
\end{equation}
\noindent
where $\tau_u$ refers to the precision of the Gaussian distribution.  It should
be noted that \pkg{R-INLA} assigns a prior to $\log(\tau_u)$ which, by default,
is a log-gamma  distribution. Although this model is not spatial, it can be
combined with other spatial models. Using $\log(\tau_u)$ instead
of simply $\tau_u$ provides some advantages as $\log(\tau_u)$ is not
constrained to be positive. This is particularly useful when optimising
to find the mode of $\log(\tau_u)$, for example.


In order to model spatial correlation, neighbourhoods must be defined among the
study areas.  It is often considered that two areas are neighbours is they
share a common boundary.  Spatial autocorrelation is modelled using a Gaussian
distribution with zero mean and a precision matrix that will model
correlation between neighbours. Given that latent effects are a GMRF, 
we can define the variance-covariance matrix of the random effects
as

\begin{equation}
\Sigma = \frac{1}{\tau} Q^{-1}
\end{equation}
\noindent
where $\tau$ is a precision parameter and matrix $Q$ encodes
the spatial structure. Given that we are assuming a latent GMRF, this also
means that matrix $Q$ will be defined such as element $Q_{ij}$ is zero if
areas $i$ and $j$ are not neighbours. This means that $Q$ is often a very
sparse matrix. See, for example, \citet{rueheld:2005} 
for details.

Available specifications for spatial dependence includes the intrinsic 
conditional autoregressive (CAR)
specification \citep{besagetal:1991}. This will produce a $Q$ matrix in which
element $Q_{ii}$ is $n_i$ (the number of neighbours of area $i$) and element
$Q_{ij}$ (with $i\neq j$) is -1 if areas $i$ and $j$ are neighbours and 0 otherwise. This
means that the spatial random effects $v_i$ are distributed as

\begin{equation}
v_i|v_j,\tau_v \sim  N( \frac{1}{n_i}\sum_{i\sim j} v_j, \frac{1}{\tau_vn_i})\ \  i\neq j
\end{equation}
\noindent
$\tau_v$ is the conditional precision of the random effects. As in the previous
model, \pkg{R-INLA} uses a log-gamma prior on $\log(\tau_v)$.

In addition, a proper version of this model is available as well,
for which the spatial random effects are distributed as

\begin{equation}
v_i|v_j,\tau_v \sim  N( \frac{1}{n_i+d}\sum_{i\sim j} v_j, \frac{1}{\tau_v(n_i+d)})\ \ i\neq j
\end{equation}
\noindent
$d$ is a positive quantity to make the distribution proper. By default,
a log-gamma distribution is assigned to $\log(d)$.

A more general approach is obtained  with the following precision
matrix:

\begin{equation}
Q = (I - \frac{\rho}{\lambda_{max}}C)
\end{equation}
\noindent
Here $I$ is the identity matrix, $\rho$ a spatial autocorrelation parameter,
$C$ an adjacency matrix and $\lambda_{max}$ the maximum eigenvalue of $C$.
\pkg{R-INLA} assigns a Gaussian prior on $\log(\rho/(1-\rho))$.
This specification ensures that $\rho$ takes values between 0 and 1.

In the following example we use the Boston housing data, which is described in
\citet{HarrisonRubinfeld:1978}, to develop an example on several spatial
models.  This data set  records median price for houses that were occupied by
their owners plus some other relevant covariates \citep[see,][for
details]{HarrisonRubinfeld:1978,pace+gilley:97}.
Data have been recorded at the tract level
and the neighbourhood structure of the tracts is also available, and it is
available in the \code{boston} data set from the \proglang{R} package
\pkg{spdep} \citep{spdep:2013}. In addition, this data set is also available in
a shapefile, which is the one we will use in this example. This will provide a 
more general example on how to load external
data into \proglang{R} to fit models with \pkg{R-INLA}.

\code{readShapePoly()}, from package \pkg{maptools}, can be used to load 
vector data from a shapefile. Alternatively, \code{readOGR()} (in package
\pkg{rgdal}) provides a more general data loading framework for vector data
since it supports a wider range of formats. This is the one we have used to
load the Boston data set:


\begin{Schunk}
\begin{Sinput}
R> library("rgdal")
R> boston<-readOGR( system.file("etc/shapes",package="spdep")[1], 
+     "boston_tracts")
\end{Sinput}
\end{Schunk}
\noindent
Here, \code{readOGR()} takes the directory where the layer (shapefile) is 
located and the layer name, which in this case is the name of the shapefile,
as arguments and return an object of type \code{SpatialPolygonsDataFrame}.
This data object is used to store the tract boundaries plus the associated
data (tract name and other variables). 

Before fitting any spatial model, the neighbourhood structure needs to be
defined.  A common criterion is to consider that two areas are neighbours if 
they share a common boundary. Function \code{poly2nb()} will take the tract
boundaries and perform this operation to provide us with the adjacency structure
of the Boston tracts as a \code{nb} object:

\begin{Schunk}
\begin{Sinput}
R> library("spdep")
R> bostonadj<-poly2nb(boston, queen=FALSE)
\end{Sinput}
\end{Schunk}
\noindent
Here, we have also set \code{queen=FALSE} so that queen adjacency is not used,
i.e., in order to consider two areas as neighbours more than one shared point
is required.  We have converted this into a binary matrix to be used with
\pkg{R-INLA} using function \code{nb2mat()}.  Furthermore, the adjacency matrix
is converted into a sparse matrix of class \code{dgTMatrix} to reduce memory
usage.  This will be passed to function \code{f()} when defining the spatial
model. 


\begin{Schunk}
\begin{Sinput}
R> adj <- nb2mat(bostonadj, style = "B")
R> adj<-as(adj, "dgTMatrix")
\end{Sinput}
\end{Schunk}
\noindent
%FIXME RSB can a graph or sparse matrix be used instead of a dense matrix? YES, FIXED.

A summary of some latent models implemented in \pkg{R-INLA}, and that can be
used within the \code{f()} function, is available in
Table~\ref{tab:inlamodels}. Note that this is not an exhaustive list and that a
complete list of the available latent models can be obtained from the
\pkg{R-INLA} documentation. We have also included a column showing whether these models are
restricted to a regular grid. Also, detailed examples are available from the
\pkg{R-INLA} website at \url{http://www.r-inla.org}.


\begin{table}[h]
\begin{center}
\begin{tabular}{lll}
Name in \code{f()}  & Model  & Regular grid\\
\hline
\code{besag} & Intrinsic CAR & No\\
\code{besagproper} & Proper CAR & No\\ 
\code{bym} & Convolution model & No  \\
%\hline[.25cm]
\code{generic0} & $\Sigma=\frac{1}{\tau}Q^{-1}$ & No\\[.25cm]
\code{generic1} & $\Sigma=\frac{1}{\tau}(I_n-\frac{\rho}{\lambda_{max}}C)^{-1}$ & No\\
%\code{rw2d} & Random walk of order 2
\code{rw2d} & 2-D random walk & Yes \\
\code{matern2d} & Mat\'ern correlation & Yes\\
\end{tabular}
\end{center}
\caption{Summary of some latent models implemented in \pkg{R-INLA} 
for spatial statistics.}
\label{tab:inlamodels}
\end{table}


Fixed effects (including the intercept) in \pkg{R-INLA}  have a Gaussian prior
with fixed mean and precision, which are 0 and  0.01 (or 0 for the intercept)
by default, respectively. These values can be changed using option
\code{control.fixed} in the \code{inla()} call. \code{control.fixed} must take
a named list of arguments, which are used to control how to handle
the fixed effects in the model. 

In this named list, \code{mean.intercept} and \code{prec.intercept} can be
used to set the parameters of the Gaussian prior of the intercept, whilst
\code{mean} and \code{prec} are the analogous parameters to define the priors
for the other fixed effects.  These can be a numeric value or another named
list, using the names of fixed effects, to set different priors for different
effects.  Note that precisions in the fixed effects priors cannot be estimated
as was the case with the different random effects presented before.

%It is worth metnioning that default values can be checked by ruuning
%\code{inla.set.control.compute.default()}.



The model that we are fitting is:

\begin{equation}
y_i = \alpha+\beta X + v_i +\varepsilon_i
\end{equation}
\noindent
where $\alpha$ is the model intercept, $\beta$ a vector of coefficients of the
covariates, $v_i$ a random effect with an intrinsic CAR specification and
$\varepsilon_i$ is random Gaussian error term. 




As \code{f()} needs an area
index which must have different values for different areas, this is first
defined in variable \code{idx}.

\begin{Schunk}
\begin{Sinput}
R> library("INLA")
R> boston$idx <- 1 : nrow(boston)
R> form <- log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2) +  
+  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)+
+  f(idx, model = "besag", graph = adj )
R> btdf<-as.data.frame(boston)
R> m1 <- inla(form, data = btdf,
+     control.predictor = list(compute = TRUE))
\end{Sinput}
\end{Schunk}

Note how the call to \code{inla()} is similar to fitting other regression
models with \proglang{R} with \code{glm()} or \code{gam()}. Furthermore, 
it is very easy to include spatial random effects with function \code{f()}
in the \code{formula} passed to \code{inla()}. Finally, \code{control.predictor = list(compute = TRUE)} is used to compute summary statistics on the
fitted values.


A summary of the model can be obtained as
follows:


\begin{Schunk}
\begin{Sinput}
R> summary(m1)
\end{Sinput}
\begin{Soutput}
Call:
"inla(formula = form, data = btdf, control.predictor = list(compute = TRUE))"

Time used:
 Pre-processing    Running inla Post-processing           Total 
         0.5950          2.3543          0.1345          3.0838 

Fixed effects:
               mean     sd 0.025quant 0.5quant 0.975quant    mode kld
(Intercept)  3.7798 0.1661     3.4536   3.7798     4.1058  3.7798   0
CRIM        -0.0073 0.0011    -0.0094  -0.0073    -0.0053 -0.0073   0
ZN           0.0003 0.0005    -0.0006   0.0003     0.0013  0.0003   0
INDUS       -0.0005 0.0024    -0.0051  -0.0005     0.0041 -0.0005   0
CHAS1       -0.0443 0.0299    -0.1030  -0.0443     0.0144 -0.0443   0
I(NOX^2)    -0.4209 0.1440    -0.7037  -0.4210    -0.1384 -0.4209   0
I(RM^2)      0.0101 0.0011     0.0080   0.0101     0.0122  0.0101   0
AGE         -0.0012 0.0005    -0.0022  -0.0012    -0.0003 -0.0012   0
log(DIS)    -0.1806 0.0719    -0.3217  -0.1806    -0.0395 -0.1806   0
log(RAD)     0.0483 0.0208     0.0076   0.0483     0.0891  0.0483   0
TAX         -0.0003 0.0001    -0.0005  -0.0003     0.0000 -0.0003   0
PTRATIO     -0.0162 0.0053    -0.0265  -0.0162    -0.0058 -0.0162   0
B            0.0006 0.0001     0.0003   0.0006     0.0008  0.0006   0
log(LSTAT)  -0.2434 0.0223    -0.2873  -0.2434    -0.1996 -0.2434   0

Random effects:
Name	  Model
 idx   Besags ICAR model 

Model hyperparameters:
                                        mean      sd       
Precision for the Gaussian observations 1.626e+04 1.707e+04
Precision for idx                       1.222e+01 7.817e-01
                                        0.025quant 0.5quant 
Precision for the Gaussian observations 7.582e+02  1.096e+04
Precision for idx                       1.074e+01  1.220e+01
                                        0.975quant mode     
Precision for the Gaussian observations 6.180e+04  1.816e+03
Precision for idx                       1.381e+01  1.216e+01

Expected number of effective parameters(std dev): 501.85(5.348)
Number of equivalent replicates : 1.008 

Marginal Likelihood:  -212.85 
Posterior marginals for linear predictor and fitted values computed
\end{Soutput}
\end{Schunk}
\noindent
The output includes summary statistics of the posterior marginals of the
coefficients of the fixed effects plus the precisions of the error term and
intrinsic CAR random effect. In addition, \code{kld} reports the
Kullback-Leibler divergence between the Gaussian and the (simplified)
Laplace approximation to the marginal posterior densities. This provides
information about the accuracy of the Gaussian approximation. 

The marginal likelihood of the model is also reported and it is computed by
integrating all the model parameters out. Hence, it is not the {\em predictive}
marginal likelihood and it can be used to perform model selection, for example.
The effictive number of parameters, as defined in
\citet{Spiegelhalteretal:2002}, and the associated number of equivalent
replicates are also shown. See \citet{isi:000284021400008} for more details on
the \pkg{R-INLA} output.

Figure~\ref{fig:marg1} shows the estimated marginals of the coefficients
of the fixed effects and the precisions of the
random effects in the model. These distributions can be used to compute summary
statistics for the model parameters. In the previous \pkg{R-INLA} output
these marginals have been used to compute the posterior mean, standard 
deviation, mode and some quantiles (0.05, 0.5 and 0.975).

%{\bf VIRGILIO: We could expand this to include the marginals of the 
%fixed effects too} %FIXME RSB It would be very helpful to explain what the figure and random effects tabulation results mean. YES, FIXED.

\begin{figure}[h]
\begin{center}
\includegraphics{spatial_inla-010}
\end{center}
\caption{Marginals of the fixed effects, and the precisions of the error term 
and spatial random effects, Boston housing data.}
\label{fig:marg1}
\end{figure}


Fitted values can be easily displayed in a map. First, we need to add
all the required values to the \code{SpatialPolygonsDataFrame}:

\begin{Schunk}
\begin{Sinput}
R> boston$LOGCMEDV <- log(boston$CMEDV)
R> boston$FTDLOGCMEDV <- m1$summary.fitted[, "mean"]
\end{Sinput}
\end{Schunk}
\noindent
Note that we will represent values in the log-scale. 
Next, we can use \code{spplot()} to display both the observed and the 
predicted  values of house prices. In the following example, which
can be seen in Figure~\ref{fig:spplot}, we have
also used package \pkg{RColorBrewer} to define a suitable colour palette:
\begin{Schunk}
\begin{Sinput}
R> library("RColorBrewer")
R> spplot(boston, c("LOGCMEDV", "FTDLOGCMEDV"),
+     cuts=8, col.regions=brewer.pal(9,"Blues"),
+     names.attr=c("Observed log-CMEDV", "Predicted log-CMEDV")
+  )
\end{Sinput}
\end{Schunk}

\begin{figure}[h!]
\begin{center}
\includegraphics{spatial_inla-014}
\end{center}
\caption{Observed and predicted median values, Boston housing data.}
\label{fig:spplot}
\end{figure}

To provide an alternative visualisation of the results, we have included a
short example using function \code{qmap()} from the \pkg{ggmap} package
\citep{KahleWickham:2013}.  First of all we will reproject our data to be
WGS84. With \code{fortify()} the \code{boston} dataset is converted into a
suitable format to be used when plotting and then the log median values are
added to the new data.

% {\bf VIRGILIO: DISPLAY DATA IN GOOGLE MAPS?}
%FIXME RSB - be *VERY* careful here as the bondaries are *NOT* WGS84 so will appear shifted if they have not been datum-transformed to the CRS("+proj=longlat +datum=WGS84") representation. The coastlines, etc, will not match without usinf spTransform. The candidate for display is the spatial random effect, I think
%\begin{figure}[h!]. YES, FIXED.


\begin{Schunk}
\begin{Sinput}
R> bostonf <- spTransform(boston, CRS("+proj=longlat +datum=WGS84"))
R> library("ggmap")
R> bostonf <- fortify(bostonf, region = "TRACT")
R> idx <- match(bostonf$id, as.character(boston$TRACT))
R> bostonf$LOGCMEDV <- boston$LOGCMEDV[idx]
\end{Sinput}
\end{Schunk}
\noindent
\code{qmap()} is based on the the grammar of graphics implemented in the
\pkg{ggplot2} package \citep{Wickham:2009}. In the next example,
\code{qmap()} is used to get satellite data from the Boston area,
whilst \code{geom_polygon()} adds the boundaries:

\begin{Schunk}
\begin{Sinput}
R> qmap('boston',
+     zoom = 10, maptype = 'satellite') +
+  geom_polygon(data=bostonf, aes(x = long, y = lat, group = group, 
+     fill=LOGCMEDV), colour = 'white', alpha = .8, size = .3)
\end{Sinput}
\end{Schunk}
\noindent
The resulting map can be seen in Figure \ref{fig:ggmap}.


\begin{figure}[h!]
\begin{center}
\includegraphics{spatial_inla-017}
\caption{Display of the Boston housing data set using \code{ggmap}
and Google Maps.} 
%FIXME RSB 140204 is the data properly in register? we need to check
\label{fig:ggmap}
\end{center}
\end{figure}



\subsection{Point patterns}

Point patterns are analysed with INLA as the result of a counting process,
i.e., points are not modelled directly but they are aggregated over a a grid
of small squares. For this reason, the analysis of point patterns is conducted
similarly to that of lattice data: counts are available for each square and 
these are assigned neighbours according to the adjacent squares. Then, counts
can be smoothed using an appropriate non-linear term, such as spatial
random effects. \citet{HossainLawson:2009} compare different approximations
to the analysis of point patterns, including methods that are based on discretisation of the study region.

In the following example we use the Japanese black pine data set from
\proglang{R} package \pkg{spatstat} \citep{spatstat:2005}. This data set records the location of
Japanese black pine saplings in a square sampling in a natural forest.  This
example is reproduced from \citet{GomezRubioetal:2013}.

Hence, we first split the study area into smaller squares to create a
grid of $10\times 10$ squares.
%, and the we aggregate the pines over the grid of $10\times 10$ squares. 

\begin{Schunk}
\begin{Sinput}
R> library("spatstat")
R> data("japanesepines")
R> japd <- as.data.frame(japanesepines)
R> Nrow <- 10
R> Ncol <- 10
R> n <- Nrow * Ncol
R> grd <- GridTopology(
+     cellcentre.offset = c(0.05, 0.05),
+     cellsize = c(1 / Nrow, 1 / Ncol), cells.dim = c(Nrow, Ncol)
+  )
\end{Sinput}
\end{Schunk}


After the creation of the grid, we have used function \code{over()} on
the set of points and the newly defined squares to find how many points can be
found in each square.

\begin{Schunk}
\begin{Sinput}
R> polygrdjap <- as(grd, "SpatialPolygons")
R> idxpp <- over(SpatialPoints(japd), polygrdjap)
R> japgrd <- SpatialGridDataFrame(grd, data.frame( Ntrees = rep(0, n) ) )
R> tidxpp <- table(idxpp)
R> japgrd$Ntrees[ as.numeric( names(tidxpp) ) ] <- tidxpp
\end{Sinput}
\end{Schunk}


Next, an index variable is built to create the spatial neighbourhood structure
to be passed to the \code{f()} function. Note that care must be taken as
\proglang{R} and \pkg{R-INLA} may have a different ordering of the areas when
defining the adjacency matrix.

\begin{Schunk}
\begin{Sinput}
R> japgrd$SPIDX <- 1 : n
R> japnb <- poly2nb(polygrdjap, queen=FALSE, row.names=1:100)
R> adjpine <- nb2mat(japnb, style = "B")
R> adjpine<-as(adjpine, "dgTMatrix")
\end{Sinput}
\end{Schunk}
\noindent
Here we have avoided using a queen adjacency as this will consider as
neighbours two areas which only share a corner.
%FIXME RSB this gives queen contiguities - is this intended? It matters much more for grids than irregular tesselations. YES, FIXED.

Finally, we define the call to \code{inla()} using a \code{formula} which
includes spatial random effects based on the grid of squares.  In addition, we
have set other options to compute the DIC, with
\code{control.compute=list(dic=TRUE)}, and the marginals of the linear
predictors, using \code{control.predictor=list(compute=TRUE)}.
We have included the specification of the prior distributions of
the log-precisions of unstructured and spatial random effects as well.

\begin{Schunk}
\begin{Sinput}
R> fpp  <-  Ntrees ~ 1 + f(japgrd$SPIDX, model = "bym", graph = adjpine,
+    hyper=list(prec.unstruct=list(prior="loggamma", param=c(0.001, 0.001) ),
+                  prec.spatial=list(prior="loggamma", param=c(0.1,0.1) ))
+  )
R> japinlala <- inla(fpp,
+     family = "poisson", data = as.data.frame(japgrd),
+     control.compute = list(dic = TRUE),
+     control.inla=list(tolerance=1e-20, h=1e-8),
+     control.predictor = list(compute = TRUE)
+  )
R> japgrd$INLALA <-  japinlala$summary.fitted.values[, "mean"]
\end{Sinput}
\end{Schunk}

The former model is the one that we have employed with the Boston data set
on an irregular lattice. Given that now we are considering a regular lattice
it is also possible to use a two-dimensional random walk for spatial
smoothing:
%FIXME in boston, besag was used, not bym

\begin{Schunk}
\begin{Sinput}
R> fpprw2d  <-  Ntrees ~ 1 + f(japgrd$SPIDX, model = "rw2d", nrow=10, ncol=10,
+    hyper=list(prec=list(prior="loggamma", param=c(0.001, 0.001) )) )
R> japinlalarw2d <- inla(fpprw2d,
+     family = "poisson", data = as.data.frame(japgrd),
+     control.compute = list(dic = TRUE),
+     control.inla=list(tolerance=1e-20, h=1e-8),
+     control.predictor = list(compute = TRUE)
+  )
R> japgrd$INLALARW2D <-  japinlalarw2d$summary.fitted.values[, "mean"]
\end{Sinput}
\end{Schunk}

\noindent
Figure~\ref{fig:sppa} shows the original counts and the smoothed counts.  Note
that this is similar to estimating the intensity of an inhomogeneous point
pattern using a smoothing method.


\begin{figure}[h]
\begin{center}
\includegraphics{spatial_inla-024}
\end{center}
\caption{Estimation of the intensity of a point pattern with \pkg{R-INLA}, 
Japanese black pine dataset.}
\label{fig:sppa}
\end{figure}



\subsection{Geostatistics}


\pkg{R-INLA} deals with geostatistical data on a regular grid. This means
that observations need to be matched to the points in the grid and that those
points with no observations attached are considered as missing values.
Hence, this is somewhat similar to the analysis of lattice data and point
patterns. However, \pkg{R-INLA} provides a number of options to build 
model-based geostatistical models \citep{DiggleRibeiro:2007}. First
of all, different likelihoods can be used. Secondly, there are different
options to define the spatial random effects. Although it is still possible
to model spatial dependence in the grid of points using a CAR specification,
\pkg{R-INLA} provides a two-dimensional Mat\'ern covariance function. 


This correlation allows, for example, the use of exponentially decaying
functions such as 

\begin{equation}
\Sigma_{ij} = \sigma^2 \exp(-d_{ij}/\varphi)
\end{equation}
\noindent
where $d_{ij}$ is the distance between points $i$ and $j$, and $\varphi$
is a parameter that controls the scale of the spatial dependence.


%
%IMPORTANT: Change the text if used in the paper
%
%In this case, the variance-covariance matrix is defined as 
%
%$$
%\Sigma_{ij}= \sigma^2 \frac{\tau^{\kappa} K(\tau, \kappa)}{2^{\kappa-1} \Gamma(\kappa)}; \tau = \alpha_{\kappa}d_{ij}/\varphi
%$$
%\noindent
%$K(\cdot, \kappa)$ is the modified Bessel function of order $\kappa$ and
%$\Gamma(\cdot)$ the Gamma function. $\alpha_{\kappa}$ and $\varphi$ can be used
%to control the scale of the spatial variation. Setting $\kappa$ to $0.5$
%leads to an exponential covariance. Other values of $\kappa$ will lead
%to other known spatial covariance functions \citep{ISI:000263326600001}.



More recently, \citet{Lindgren:2011} follow a different approach based on
a triangulation on the sampling points and the use of stochastic partial
differential equations. Now, the spatial effects are defined as

\begin{equation}
u(s)=\sum_{k=1}^n \psi_k(s)w_k,\ s\in \mathbb{R}^2
\end{equation}
\noindent
Here, $\{\psi_k(s)\}$ are a basis of functions and $w_k$ are associated
weights. Weights are assumed to be Gaussian. The advantages of this approach
for spatial statistics are fully described in \citet{Camelettietal:2013}.


In order to show how to fit geostatistical models with \pkg{R-INLA} we
reproduce here an example from \citet{GomezRubioetal:2013} based on the
Rongelap data set \citep{DiggleRibeiro:2007}, which records  radionuclide
concentration at 157 different locations in Rongelap island. We have restricted
the analysis to one of the clusters in the north-east part of the island
because observations need to be matched to a regular grid of points.  For this
analysis we have used \proglang{R} packages \pkg{geoR} \citep{geoR:2001} and
\pkg{geoRglm} \citep{geoRglm:2002}.



First of all, data are loaded and the data from the desired clusters
are extracted from the original data set by checking that their coordinates
are in the window $(-700, -500)\times (-1900, -1700)$.

\begin{Schunk}
\begin{Sinput}
R> library("geoR")
R> library("geoRglm")
R> data("rongelap")
R> rgldata <- as.data.frame(rongelap)
R> xy <- rongelap[[1]]
R> idx1 <- (xy[,1] < -500 & xy[,1] > -700 & 
+     xy[,2] > -1900 & xy[,2] < -1700)
R> rgldata <- rgldata[idx1, ]
\end{Sinput}
\end{Schunk}


The next step is to  define the grid topology for the grid that will be
used to match these points to. The grid is defined to be of dimension 
$5\times 5$. 

\begin{Schunk}
\begin{Sinput}
R> Nrow <- 5
R> Ncol <- 5
R> n <- Nrow * Ncol
R> grdoffset <- c( min(rgldata$X1), min(rgldata$X2) )
R> csize1 <- diff( range(rgldata$X1) ) / (Nrow-1)
R> csize2 <- diff( range(rgldata$X2) ) / (Ncol-1)
R> grd <- GridTopology(
+     cellcentre.offset = grdoffset, 
+     cellsize = c(csize1, csize2),
+     cells.dim = c(Nrow, Ncol)
+  )
\end{Sinput}
\end{Schunk}
\noindent
Data will be placed in a \code{SpatialGridDataFrame} (using the previously
defined grid topology) and re-organised according to what \pkg{R-INLA} expects
for this model (i.e., grid data stored by column).  An index variable \code{IDX}
is added to be used in \code{f()} when defining the model. However, 
\pkg{R-INLA} will rely on how the rows are ordered in the data passed to 
\code{inla()} when defining distances and adjacencies (i.e., the index
variable ordering will not be considered).

\begin{Schunk}
\begin{Sinput}
R> inla2sp <- inla.lattice2node.mapping(Nrow, Ncol)[ , Ncol:1]
R> inla2sp <- as.vector(inla2sp)
R> spgrd <- SpatialGridDataFrame(grd, as.data.frame(rgldata[inla2sp, ]) )
R> spgrd$IDX <- 1 : nrow(spgrd@data)
\end{Sinput}
\end{Schunk}


Next, we create a \code{SpatialPolygons} with the boundaries of the squares
in the grid. This way, it is easy to match the data to the newly created grid using function
\code{over()}.


\begin{Schunk}
\begin{Sinput}
R> polygrd <- as(grd, "SpatialPolygons")
R> dataidx <- over(SpatialPoints( as.matrix(rgldata[, 1:2]) ), polygrd)
\end{Sinput}
\end{Schunk}

It should be noted that  radionuclide concentration is measured at each square
by the average of the observations in the square, and this needs
to be computed beforehand.


\begin{Schunk}
\begin{Sinput}
R> yag <- by(rgldata$data, dataidx, sum)
R> umag <- by(rgldata$units.m, dataidx, sum)
R> ratioag <- yag / umag
\end{Sinput}
\end{Schunk}

Then, a new column is added to the \code{SpatialGridDataFrame} with these
averages. \code{NA} will be used for
the squares with no data so that these values will be imputed from the model.
\begin{Schunk}
\begin{Sinput}
R> spgrd$ratioag <- NA
R> spgrd$ratioag[ as.numeric(names(ratioag)) ] <- ratioag
\end{Sinput}
\end{Schunk}

Here we define a model with an intercept term and a random effect of the
Mat\'ern class. Note how we have fixed, for convenience, 
the value of the range and precision.

\begin{Schunk}
\begin{Sinput}
R> formula1 <-  ratioag ~ 1 + f(spgrd$IDX, model = "matern2d", 
+     nrow = Nrow, ncol = Ncol,
+     hyper = list(range = list(initial = log(sqrt(8)/.5), fixed = TRUE),
+              prec = list(initial = log(1), fixed = TRUE)))
R> rglinlala <- inla(formula1, family = "poisson",
+     control.predictor = list(compute = TRUE),
+     control.compute = list(dic = TRUE),
+     data = as.data.frame(spgrd) )
R> spgrd$INLALA <- rglinlala$summary.fitted.values[,"mean"]
\end{Sinput}
\end{Schunk}
Similarly as in the point patterns example, here we have also used
a two dimensional random walk for spatial smoothing.

%{\bf Check that data have the right ordering for the rw2d.}


\begin{Schunk}
\begin{Sinput}
R> formularw2d <-  ratioag ~ 1 + f(spgrd$IDX, model = "rw2d",
+     nrow = Nrow, ncol = Ncol,
+        hyper=list(prec=list(prior="loggamma", param=c(1, 1) )) )
R> rglinlalarw2d <- inla(formularw2d, family = "poisson",
+     control.predictor = list(compute = TRUE),
+     control.compute = list(dic = TRUE),
+     data = as.data.frame(spgrd) )
R> spgrd$INLALARW2D <- rglinlalarw2d$summary.fitted.values[,"mean"]
\end{Sinput}
\end{Schunk}



Figure~\ref{fig:geos} shows the observed and estimated radionuclide
concentration in Rongelap island. It can be seen how our model has spatially
smoothed the observed values.

\begin{figure}[h]
\begin{center}
\includegraphics{spatial_inla-033}
\caption{Observed  and estimated radionuclide concentration
in Rongelap island.}
\label{fig:geos}
\end{center}
\end{figure}

\subsection[{R-INLA} and other packages for Bayesian spatial modelling]{\pkg{R-INLA} and other packages for Bayesian spatial modelling}

\pkg{R-INLA} is not the only package for Bayesian spatial modelling.
\citet[Chapter 10]{Bivandetal:2013} compare different packages for Bayesian
modelling in the contect of disease mapping. We wil focus here in \pkg{R2BayesX}
%\citep{Brezgeretal:2005} 
%FIXME RSB 140204 no reference here - unfortunately, JSS-931 Structured Additive Regression Models: An R Interface to BayesX, Authors: Umlauf, Adler, Kneib, Lang, Zeileis is still in final screening. VIRGILIO: Ref. removed for now.
because it provides a way to defining spatial models as
\pkg{R-INLA}.


For example, in order to reproduce the example on the Japanesse black pine
data with \pkg{R2BayesX} we can do the following:

\begin{Schunk}
\begin{Sinput}
R> library("R2BayesX")
R> bayesxadj<-nb2gra(japnb)
R> japbayesx<-bayesx(Ntrees ~ 1+sx(SPIDX, bs="re")+sx(SPIDX,bs="spatial", 
+     map=bayesxadj), family="poisson", data=as.data.frame(japgrd))
\end{Sinput}
\end{Schunk}

\noindent
Function \code{nb2gra()} is used to convert our adjacency matrix into
an object of class \code{gra}, which is used in \pkg{R2BayesX} to store 
adjacencies. \code{bayesx()} takes similar arguments as \code{inla()}
and the model can be expressed using a \code{formula}, with \code{sx()}
used to define the random effects. \code{sx(idx, bs="re")} defines
independent Gaussian random effects and  the spatial random effects
are defined in 
\code{sx(TRACT,bs="spatial", map=bayesxadj)}
 using adjancency matrix defined in \code{bayesxadj}.

Retrieving the predicted data requires some care as they are reordered,
but is is as simple as:
\begin{Schunk}
\begin{Sinput}
R> japgrd$BAYESX<-japbayesx$fitted.values[order(japbayesx$bayesx.setup$order),
+     "mu"]
\end{Sinput}
\end{Schunk}
\noindent
Finally, we compare the fitted values obtained with \pkg{R-INLA} and
\pkg{R2Bayes} in Figure~\ref{fig:inlabayesx}. Note that differences appear
not only
because of the different models used but also because of the choice of
prior distributions.



\begin{figure}[h]
\begin{center}
\includegraphics{spatial_inla-036}
%FIXME RSB 140204 wrong data set, should be Japanese pines. YES, FIXED.
\caption{Estimation of the intensity of a point pattern with \pkg{R-INLA} and \pkg{BayesX}, Japanese black pine dataset.}
\label{fig:inlabayesx}
\end{center}
\end{figure}





\section[Extending {R-INLA} to fit new models]{Extending \pkg{R-INLA} to fit new models} 

\label{sec:extINLA}


Although the current implementation of INLA in the \pkg{R-INLA} package
provides a reasonable number of models for spatial dependence it may be the
case that we need to include some other models. As it is now, this is not
possible without adding to the code of the external INLA programme.

\citet{Bivandetal:2014} describe a simple way of extending INLA to use other
latent models.  In particular they focus on some latent models used in spatial
econometrics that are not available as part of the \pkg{R-INLA} package at
the moment. A new latent class has been added recently and it is
described in \citet{GomezRubioetal:2014}.

This approach is based on considering a model where one or several parameters have been
fixed in a way that makes the conditioned model fittable with \pkg{R-INLA}.  If
we denote by $\rho$ the vector of parameters to fix and by $\hat{\rho}$ a
specific set of fixed parameter values,  the full posterior marginal could be
written as


\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \hat{\rho}) 
\end{equation}
\noindent
Taking this into account,  it is clear that when conditioning on
$\rho=\hat\rho$ \pkg{R-INLA} will give us an approximation to
$\pi(x_i|\mathbf{y}, \hat{\rho})$ and $\pi(\theta_i|\mathbf{y}, \hat{\rho})$.



Note that the full posterior distribution can be obtained by integrating $\rho$
out, i.e.,

\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}) = 
\int \pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \rho)\pi(\rho|\mathbf{y})d\rho
\label{eq:fullpost}
\end{equation}
\noindent
where $\pi(\rho|\mathbf{y})$ is the posterior distribution of $\rho$. Also,
note that this can be written as

\begin{equation}
\pi(\rho|\mathbf{y}) \propto \pi(\mathbf{y}|\rho) \pi(\rho)
\label{eq:postrho}
\end{equation}
\noindent
Here $\pi(\rho)$ is a prior distribution on $\rho$ and $\pi(\mathbf{y}|\rho)$
is the marginal likelihood of the model, which is reported by \pkg{R-INLA}.
Hence, $\pi(\rho|\mathbf{y})$ can be estimated by re-scaling
expression in Equation~\ref{eq:postrho}.


The posterior distribution of $\rho$ can be estimated by defining a fine grid
of values $S=\{\rho_i\}_{i=1}^r$ so that $\pi(\rho_i|\mathbf{y}),\ i=1,
\ldots,r$ are computed.  Then $\pi(\rho|\mathbf{y})$ can be obtained by fitting
and re-scaling a spline (or other non-linear function) to the previous values.
Using simple numerical integration techniques we can obtain an approximation to
$\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y})$ as follows:

\begin{equation}
\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}) = \int \pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \rho)\pi(\rho|\mathbf{y})d\rho
\simeq
\sum_{\rho_i\in S}\pi(\mathbf{x}, \mathbf{\theta}|\mathbf{y}, \rho_i)  
\pi(\rho_i|\mathbf{y}) \Delta_i
\label{eq:fullpostapp}
\end{equation}
\noindent
where $\Delta_i$ is the amplitude of the interval used in the discretisation
of $\rho$.

Note that the previous expression can be regarded as a weighted average
of the different models fitted after conditioning on different values of
$\rho$.

From Equation~\ref{eq:fullpostapp} it is clear that we can obtain the following
approximations to the posterior marginals of the individual latent parameters
and hyperparameters:

\begin{equation}
\hat{\pi}(x_i|\mathbf{y}) = \sum_j \pi(x_i|\mathbf{y}, \rho_j) w_j
\end{equation}

\begin{equation}
\hat{\pi}(\theta_i|\mathbf{y}) = \sum_j \pi(\theta_i|\mathbf{y}, \rho_j) w_j
\end{equation}
\noindent
$w_j$ is a weight associated with $\rho_j$ as follows:

\begin{equation}
w_j = \pi(\rho_j|\mathbf{y})\Delta_j
\end{equation}


This is like carrying out Bayesian model averaging \citep{Hoetingetal:1999} on the
different conditioned models fitted with \pkg{R-INLA}. Altogether, this
provides a way of combining simpler models to obtain our desired model. In
Section~\ref{sec:examples} we show how to apply these ideas to different models
in spatial statistics.


%If $\rho$ is a discrete parameter with values in a (finite) set $S$, this can 
%be done by
%
%$$
%\pi(\rho|\mathbf{y}) = \frac{\pi(\mathbf{y}|\rho) \pi(\rho)}{\sum_{\rho_i\in S} \pi(\mathbf{y}|\rho_i) \pi(\rho_i) }
%$$

Note that this approach can be easily extended to the case of $\rho$ being
a discrete random variable.


\subsection{Implementation}

We have implemented this approach in an \pkg{R} package called \pkg{INLABMA},
available from CRAN.
%\url{http://R-forge.R-project.org} as part of the \code{spdep2} project.\footnote{For installation: \code{ install.packages("INLABMA", repos="http://R-Forge.R-project.org")}.} %FIXME RSB should link be to actual package? YES, FIXED.
The package includes some
general functions to conduct Bayesian model averaging of models fitted with
INLA. In addition, we have included some wrapper functions to fit the models
described in Section~\ref{sec:examples}.


\section{Examples}
\label{sec:examples}

\subsection{Leroux model}

\citet{Lerouxetal:1999} propose a model for the analysis of spatial data in a
lattice which is similar to the one by \citet{besagetal:1991}, in the sense
that they split variation according to  spatial and non-spatial patterns.
Rather than including the spatial and non-spatial random effect as a sum in the
linear term they consider a single random effect as follows:

\begin{equation}
u \sim MVN(0, \Sigma);\ \Sigma=\sigma^2 ((1-\lambda) I_n+\lambda M)^{-1}
\label{eq:leroux}
\end{equation}
\noindent
Here $M$ is the precision matrix of a process with spatial structure and we
will take that of an intrinsic CAR specification. Hence, the precision matrix
is, in a sense, a mixture of the precisions of a non-spatial and a spatial
one. $\lambda$ controls how strong the spatial structure is. For $\lambda=1$
the effect is entirely spatial whilst for $\lambda=0$ there is no spatial
dependence.

In principle, this is not a model that \pkg{R-INLA} can fit. However, if
$\lambda$ is fixed, then the random effects are Gaussian with a known structure
for the variance-covariance matrix which can be fitted using a \code{generic0}
latent model.

\subsubsection{Boston housing data}

Here we revisit the Boston housing data to fit the Leroux et al. model.  First
of all, it is worth mentioning that the model needs a wrapper function to be
fitted for a given value of the spatial parameter $\lambda$. This wrapper
function is included in the \proglang{R} package \pkg{R-INLA} and it is based
on the \code{generic0} latent model available in  \pkg{R-INLA}.  Once $\lambda$
is fixed the model can be easily fitted with \pkg{R-INLA}, as the latent effect
is a multivariate Gaussian random effect with zero mean and precision matrix as
in Equation~\ref{eq:leroux}.  We repeat this procedure for different values of
$\lambda$ to obtain a list of fitted models to be combined later.

Hence, we have written a simple wrapper function which is included in package \pkg{INLABMA}:

\begin{Schunk}
\begin{Sinput}
R> library("INLABMA")
R> leroux.inla
\end{Sinput}
\begin{Soutput}
function (formula, d, W, lambda, improve = TRUE, fhyper = NULL, 
    ...) 
{
    W2 <- diag(apply(W, 1, sum)) - W
    Q <- (1 - lambda) * diag(nrow(W)) + lambda * W2
    assign("Q", Q, environment(formula))
    if (is.null(fhyper)) {
        formula <- update(formula, . ~ . + f(idx, model = "generic0", 
            Cmatrix = Q))
    }
    else {
        formula <- update(formula, . ~ . + f(idx, model = "generic0", 
            Cmatrix = Q, hyper = fhyper))
    }
    res <- inla(formula, data = d, ...)
    if (improve) 
        res <- inla.rerun(res)
    res$logdet <- as.numeric(Matrix::determinant(Q)$modulus)
    res$mlik <- res$mlik + res$logdet/2
    return(res)
}
<environment: namespace:INLABMA>
\end{Soutput}
\end{Schunk}


In the previous code, the precision matrix \code{Q} is created using the
adjacency matrix \code{W} and the value of $\lambda$. Then the \code{generic0}
model is added to the formula with the fixed effects. Finally we correct the
marginal log-likelihood $\pi(\mathbf{y|\lambda})$ (conditioned on the value of
$\lambda$) by adding half the log-determinant of $((1-\lambda)I_n+\lambda M)$.
Note that, in principle, this is not needed to fit a single model and obtain
the approximations to the posterior marginals as it is a constant. However, we
are fitting and combining several models so we need to correct for this because
this scaling factor will change with the value of $\lambda$.  Argument
\code{'...'} is used to pass any other options to \code{inla()}.  This can be
used to tune and set a number of other options.

%Similar wrapper functions can be written for other models. The functions
%included in package \pkg{INLABMA} are similar, but include further options
%\citep[see,][for details]{Bivandetal:2014}.

%Note that here \code{zero.variance} is used to set
%to zero the additional error term which is added by default by \pkg{R-INLA}.


Also, the adjacency matrix is taken from the data provided in the \code{boston}
data set.
Note that we will be using a binary adjacency matrix as the random
effects have an intrinsic CAR specification:
\begin{Schunk}
\begin{Sinput}
R> boston.matB <- listw2mat(nb2listw(bostonadj, style = "B"))
R> bmspB <- as(boston.matB, "CsparseMatrix")
\end{Sinput}
\end{Schunk}

Function \code{inla.leroux} is used in the example below to compute the fitted
models for the Leroux et al. model.  In this case, we take $\lambda$ to be in
the interval $(0.8,0.99)$ after previous assessment on where
$\pi(\lambda|\mathbf{y})$ has its mode. Also, we define a prior for the
precision of the random effects in variable \code{fhyper}.  The prior for the
precision of the error term is defined in \code{errorhyper}. In addition, we
have used \code{mclapply} to parallelise the computations on operating systems
supporting forking (not Windows). Note that this is an advantage of fitting
these conditioned models compared with standard MCMC methods.

\begin{Schunk}
\begin{Sinput}
R> rlambda <- seq(0.8, 0.99, length.out = 20)
R> fhyper <- list(prec = list(prior = "loggamma", 
+     param = c(.001,.001), initial = log(1), fixed = FALSE))
R> errorhyper <- list(prec = list(prior = "loggamma",
+     param = c(.001,.001), initial = log(1), fixed = FALSE))
R> form2 <- log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2) + 
+      AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT)
\end{Sinput}
\end{Schunk}



\begin{Schunk}
\begin{Sinput}
R> lerouxmodels = mclapply(rlambda,
+          function(lambda) {
+                  leroux.inla(form2, d = as.data.frame(boston), 
+  		   W = bmspB, lambda = lambda,
+                     fhyper = fhyper, improve=TRUE,
+                     family = "gaussian",
+  		   control.fixed = list(prec.intercept=.001, prec=.001),
+  		   control.family = list(hyper=errorhyper),
+                     control.predictor = list(compute = TRUE),
+                     control.compute = list(dic = TRUE, cpo = TRUE),
+                     control.inla = list(print.joint.hyper = TRUE)
+                  )
+          })
\end{Sinput}
\end{Schunk}





Following this, we need to combine the different models to obtain the final
model by Bayesian Model Averaging. We will take a uniform prior on $\rho$ and
set the third argument in the following function to $\log(1)=0$. Note that
another prior can be used here by giving the log-density of the prior at the
different values of $\rho$.



\begin{Schunk}
\begin{Sinput}
R> bmaleroux <- INLABMA(lerouxmodels, rlambda, 0, impacts=FALSE)
\end{Sinput}
\end{Schunk}


\noindent
\code{bmaleroux} is similar to the object returned by \code{inla()} and it
includes the posterior marginals and summary statistics for $\lambda$
in a list element named \code{rho}. This provides summary statistics (mean,
standard deviation and some quantiles) and the posterior marginal.

The same model can be fitted using package \pkg{CARBayes} \citep{CARBayes:2013}
as follows:

\begin{Schunk}
\begin{Sinput}
R> library("CARBayes")
\end{Sinput}
\end{Schunk}
\begin{Schunk}
\begin{Sinput}
R> bostondf<-as.data.frame(boston)
R> attach(bostondf)
R> lcarbayes <-  lerouxCAR.re (form2, W = boston.matB, family="gaussian",
+     burnin = 1000,  n.sample = 11000, thin = 5, prior.rho=rlambda)
R> detach(bostondf)
R> rm(bostondf)
\end{Sinput}
\end{Schunk}


Table~\ref{tab:leroux} shows point estimates and standard deviations of the
fixed effects and parameter $\lambda$ (bottom line) in the model. It is clear
that there are no significant differences between the estimates computed with
MCMC and our method.  Furthermore, Figure~\ref{fig:leroux} shows the marginal
distribution of $\lambda$ and it shows how our estimate is very close to that
provided by MCMC. 
Figure~\ref{fig:leroux} also shows a good agreement between the posterior
means of the fitted values. 

%The slight difference that is observed may well be due to the
%fact that different priors have been used for the variances of the random
%effects and the error term. \pkg{CARBayes} uses uniform priors on the variances,
%whiles \pkg{R-INLA} assigns inverted Gamma distributions to the variances.

%However, we have found that our estimates
%of the posterior marginals of the precisions differ from those obtained
%with MCMC. This may be due to the high correlation between these two parameters
%(-0.9, computed using the MCMC samples) which may cause some confunding in the
%model.

% latex table generated in R 3.1.0 by xtable 1.7-3 package
% Fri Jul 18 13:30:11 2014
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Mean (INLA) & SD (INLA) & Mean (MCMC) & SD (MCMC) \\ 
  \hline
(Intercept) & 3.8055 & 0.1770 & 3.7879 & 0.1611 \\ 
  CRIM & -0.0076 & 0.0011 & -0.0076 & 0.0011 \\ 
  ZN & 0.0003 & 0.0005 & 0.0003 & 0.0004 \\ 
  INDUS & -0.0006 & 0.0023 & -0.0003 & 0.0023 \\ 
  CHAS1 & -0.0338 & 0.0302 & -0.0323 & 0.0300 \\ 
  I(NOX\verb|^|2) & -0.4374 & 0.1412 & -0.4219 & 0.1406 \\ 
  I(RM\verb|^|2) & 0.0099 & 0.0011 & 0.0099 & 0.0011 \\ 
  AGE & -0.0011 & 0.0005 & -0.0011 & 0.0005 \\ 
  log(DIS) & -0.1663 & 0.0616 & -0.1620 & 0.0597 \\ 
  log(RAD) & 0.0506 & 0.0205 & 0.0512 & 0.0195 \\ 
  TAX & -0.0003 & 0.0001 & -0.0003 & 0.0001 \\ 
  PTRATIO & -0.0164 & 0.0053 & -0.0163 & 0.0054 \\ 
  B & 0.0006 & 0.0001 & 0.0006 & 0.0001 \\ 
  log(LSTAT) & -0.2534 & 0.0227 & -0.2525 & 0.0234 \\ 
  lambda & 0.9520 & 0.0315 & 0.9423 & 0.0326 \\ 
   \hline
\end{tabular}
\caption{Point estimates of fixed effects and $\lambda$ using INLA and MCMC.} 
\label{tab:leroux}
\end{table}

\begin{figure}[h]
\begin{center}
\includegraphics{spatial_inla-051}
\end{center}
\caption{Comparisson between the posterior marginals of several parameters in 
Leroux et al.'s model and fitted values with INLA (red) and MCMC (black).}
\label{fig:leroux}
\end{figure}

While writting this paper, \citet{LeeMitchell:2013} have come up with an
alternative way of fitting this model using \pkg{R-INLA} and a \code{generic1}
latent model. In general, the results obtained for $\lambda$ with our approach
are very similar to the ones obtained with theirs for the Boston housing data.








\subsection{Spatial econometrics models}

\citet{LeSagePace:2009} describe in detail a range of models used in spatial
econometrics. These models have been developed to make the
dependence among the observed values $y_i$ explicit. First of all, spatial dependence
can be assumed on the error term (SEM model), so that we have a slightly different model:

\begin{equation}
y= \alpha+\beta X +u; u=\rho W u+\varepsilon
\end{equation}
\noindent
Here the error term $u$ is assumed to have spatial dependence.  $\rho$ is a
parameter that controls spatial autocorrelation, $\alpha$ is the intercept, $X$
a design matrix of covariates and $\beta$ a vector of associated coefficients.
$\varepsilon$ is an error term which is Gaussian with zero mean and
variance-covariance matrix $\Sigma$. Here, $\Sigma = \sigma^2 I_n$ with $I_n$
being a $n\times n$ identity matrix and $\sigma^2$ is the variance of the error
term.


The adjacency matrix $W$ is often taken to be row-standardised \citep[see, for
example,][]{Haining:2003} to ensure that $\rho$ is in the interval $(-1, 1)$.
Also, when $\rho$ is equal to zero there is no spatial dependence.

This can be reformulated as

\begin{equation}
y= \alpha+\beta X+\varepsilon'
\end{equation}
\noindent
$\varepsilon'$ is now an error term with a Gaussian distribution with zero
mean and variance-covariance matrix $\Sigma=\sigma^2((I_n-\rho W)(I_n-\rho W^\top))^{-1}$.
Note that this variance-covariance encodes spatial dependence in a particular
way and that this is often referred to as Simultaneous Autoregressive (SAR)
specification \citep[see, for example,][]{cressie:1993}.%FIXME RSB refer to Ripley 1981 or Cressie. YES, FIXED.


Alternatively, autocorrelation can be modelled explicitly so that the
variable response $y$ depends on itself. This is the Spatial Lag Model
(SLM model) and it can be defined as follows:

\begin{equation}
y= \alpha+\beta X+\rho W y +\varepsilon 
\end{equation}
\noindent
This model can be reformulated as

\begin{equation}
y = (I_n-\rho W)^{-1}(\alpha+\beta X)+\varepsilon' 
\label{eq:slm}
\end{equation}
\noindent
where $\varepsilon'$ is a Gaussian term with zero mean and
variance-covariance matrix with a SAR specification.

In addition to the previous models, sometimes lagged covariates are 
added to include the effects of neighbouring covariates. This is known
as Spatial Durbin Model (SDM)  and it is often expressed as

\begin{equation}
y= \rho W y+ \alpha+\beta X+\gamma W X +\varepsilon 
\end{equation}
\noindent
which leads to

\begin{equation}
y= (I_n-\rho W)^{-1}(\alpha+\beta X+\gamma W X) +\varepsilon'
\end{equation}
\noindent
Note that this is like our previous model in Equation~\ref{eq:slm} using an extended
design matrix that includes both $X$ and $W X$.

These models cannot be fitted with \pkg{R-INLA} for two reasons. First of all, 
the SAR specification is not implemented, so we cannot consider it for our
error terms. Furthermore, it is not possible to define a model 
where the linear predictor is multiplied by $(I_n-\rho W)^{-1}$.

Following Section~\ref{sec:extINLA}, it should be noted that, for a fixed
$\rho$, these models become standard linear models with a particular 
(but known) design matrix for the fixed effects and a multivariate Gaussian
distribution for the error term with zero mean and variance-covariance matrix.

This model can be easily fitted using \pkg{R-INLA} for different values
of $\rho$. Note that, according to \citet{Haining:2003}, $\rho$ is constrained 
to be in the interval $(1/\lambda_{min}, 1/\lambda_{max})$, with
$\lambda_{min}$ and $\lambda_{max}$ the minimum and maximum eigenvalues of
the adjacency matrix $W$. For row standardised adjacency matrices we have that
$\lambda_{max}=1$ and then $\rho$ is lower than 1. Furthermore, we are often
interested in positive spatial autocorrelation and, in practice, we will
assume that $\rho$ is in the interval $[0,1)$.


Finally, we have considered here the Gaussian case, but it is very easy to
extend this model to consider other likelihoods. In particular,
\citet{LeSageetal:2011} describe a Spatial Probit model where the outcome is
whether an event occurred. Hence, the response and the linear predictors are
linked via a probit function as follows:

\begin{equation}
y_i=
\left\{
\begin{array}{cc}
1 & if y^*_i\geq 0\\
0 & if y^*_i < 0
\end{array}
\right.
\end{equation}

The previous approach can be used here as well. The same code will still work
as we can define a different family and link function to be used when calling
\code{inla()}.

\subsubsection{Boston housing data}

Here we revisit the Boston housing data to fit the three models on Spatial
Econometrics previously described. First of all, it is worth mentioning that
each models needs a wrapper function to be fitted for a given value of the
spatial autocorrelation parameter $\rho$. These wrapper functions are included
in \proglang{R} package \pkg{R-INLA}.

All functions are based on the \code{generic0} model available in  \pkg{R-INLA}.
This model implements a multivariate Gaussian random effect with zero mean
and precision matrix $\tau Q$. Once $\rho$ is fixed, $Q$ is
known and the model can be easily fitted with \pkg{R-INLA} for that value of
$\rho$. We repeat this procedure for different values of $\rho$ to
obtain a list of fitted models to be combined later.

A simple wrapper function can be defined as follows for the SEM model:

\begin{Schunk}
\begin{Sinput}
R> semwr.inla <- function(formula, d, W, rho, ...) {
+      IrhoW <- diag(nrow(W)) - rho * W
+      IrhoW2 <- t(IrhoW) %*% IrhoW
+      environment(formula) <- environment()
+      formula <- update(formula, . ~ . + f(idx, model = "generic0", 
+          Cmatrix = IrhoW2))
+      res <- inla(formula, data = d, ...)
+      res$logdet <- as.numeric(determinant(IrhoW2)$modulus)
+      res$mlik <- res$mlik + res$logdet/2
+      return(res)
+  }
\end{Sinput}
\end{Schunk}

In the previous code, the precision matrix \code{IrhoW2} is created using the
adjacency matrix and the value of $\rho$ and the \code{generic0} model is added
to the formula after the fixed effects. As discussed with the Leroux model, the
marginal log-likelihood $\pi(\mathbf{y|\rho})$  (note that now we are
conditioning on $\rho$) is corrected by adding half the log-determinat of
$(I_n-\rho W^\top)(I_n-\rho W)$.  Argument \code{'...'} is used, again, to pass any other
options to \code{inla()}.

Similar wrapper functions can be written for the other models. The functions
included in package \pkg{INLABMA} are similar, but include further options,
to improve fitting or compute the impacts 
\citep[see,][for details]{Bivandetal:2014}.

This is used in the following example to compute the fitted models
for the SEM model. Note that here \code{zero.variance} is used to set
to zero the additional error term which is added by default by \pkg{R-INLA}.
Also, the adjacency matrix is taken from the data provided in the \code{boston}
data set.

\begin{Schunk}
\begin{Sinput}
R> zero.variance = list(prec = list(initial = 25, fixed = TRUE))
R> boston.mat <- nb2mat(bostonadj)
R> bmsp <- as(boston.mat, "CsparseMatrix")
R> boston$idx <- 1:nrow(boston)
R> fform <- log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + 
+      I(RM^2) + AGE + log(DIS) + log(RAD) + TAX + PTRATIO + 
+      B + log(LSTAT)
\end{Sinput}
\end{Schunk}

Next, we define a fine grid on the interval $(0,1)$ to give values
to $\rho$ and compute the different models under these values. Again,
we have used \code{mclapply}  to speed up computations.


\begin{Schunk}
\begin{Sinput}
R> rrho1 <- seq(0.5, 0.9, len = 20)
\end{Sinput}
\end{Schunk}
\begin{Schunk}
\begin{Sinput}
R> semmodels = mclapply(rrho1,
+          function(rho) {
+                  sem.inla(fform, d = as.data.frame(boston), W = bmsp,
+  			rho = rho, family = "gaussian", impacts = FALSE,
+                          control.family = list(hyper = zero.variance),
+                          control.predictor = list(compute = TRUE),
+                          control.compute = list(dic = TRUE, cpo = TRUE),
+                          control.inla = list(print.joint.hyper = TRUE)
+                  )
+          })
\end{Sinput}
\end{Schunk}

\noindent
Following this, we need to combine the different models
to obtain the final model by Bayesian Model Averaging. As in the
example using the Leroux model, we will take
a uniform prior on $\rho$ and set the third argument in the following
function to $\log(1)=0$. 

\begin{Schunk}
\begin{Sinput}
R> bmasem <- INLABMA(semmodels, rrho1, 0 , impacts = FALSE)
\end{Sinput}
\end{Schunk}

\code{bmasem} is similar to the object returned by \code{inla()} and it
includes the posterior marginals and summary statistics for $\rho$.

SLM and SDM models can be fitted using similar code. In the case of
the SLM, first we compute the design matrix (of the fixed effects) 
to be used later when fitting the models. This will speed up the 
computations.

\begin{Schunk}
\begin{Sinput}
R> mmatrix <- model.matrix(fform, as.data.frame(boston))
R> rrho2 <- seq(0.3, 0.6, len = 20)
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
R> slmmodels = mclapply(rrho2,
+          function(rho) {
+                  slm.inla(form, d = as.data.frame(boston), W = bmsp,
+  			rho = rho, mmatrix = mmatrix,
+                          family = "gaussian", impacts = TRUE,
+                          control.family = list(hyper = zero.variance),
+                          control.predictor = list(compute = TRUE),
+                          control.compute = list(dic = TRUE, cpo = TRUE),
+                          control.inla = list(print.joint.hyper = TRUE)
+                  )
+          })
R> 
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
R> bmaslm <- INLABMA(slmmodels, rrho2, 0 , impacts = FALSE)
\end{Sinput}
\end{Schunk}

In the case of the SDM, it is very helpful to compute $X$ and $WX$ beforehand
to reduce computation time, as this is common to all the fitted models
regardless of the value of $\rho$. This can be later passed to wrapper function
\code{sdm.inla}.

\begin{Schunk}
\begin{Sinput}
R> mmW <- bmsp %*% mmatrix[,-1]#Remove intercept
R> mmatrixsdm <- cbind(mmatrix, as.matrix(mmW) )
R> rrho3 <- seq(0.4, 0.7, len = 20)
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
R> sdmmodels = mclapply(rrho3,
+          function(rho) {
+                  sdm.inla(form, d = as.data.frame(boston), W = bmsp,
+  			rho = rho, mmatrix = mmatrixsdm,
+                          family = "gaussian", impacts = TRUE,
+                          control.family = list(hyper = zero.variance),
+                          control.predictor = list(compute = TRUE),
+                          control.compute = list(dic = TRUE, cpo = TRUE),
+                          control.inla = list(print.joint.hyper = TRUE)
+                  )
+          })
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
R> bmasdm <- INLABMA(sdmmodels, rrho3, 0 , impacts = FALSE)
\end{Sinput}
\end{Schunk}

As we have seen in the previous examples, combining the different values 
for the different values of $\rho$ provides accurate estimates of the posterior
marginals for the model parameters. The estimates of the marginals of
$\rho$ can be found in Figure~\ref{fig:pmargrho}.

\begin{figure}[h]
\begin{center}
\includegraphics{spatial_inla-067}
\end{center}
\caption{Posterior marginal of the spatial autocorrelation parameter $\rho$
for different spatial econometrics models, Boston housing data.}
\label{fig:pmargrho}
\end{figure} 


\section{Discussion} \label{sec:disc}

The integrated nested Laplace approximation has provided a new paradigm to
model fitting in Bayesian analysis. By focusing on the marginals and providing
an interesting computational approach, it has become a reasonable and faster
alternative to MCMC. Furthermore, the \pkg{R-INLA} package makes model fitting
in \proglang{R} a very simple task.  Although \pkg{R-INLA} implements some key
models, there are some others that have not been implemented yet.
In addition, it is not easy to implement completely new models within 
\pkg{R-INLA}. Latent mixture models are an important example of models that
cannot be fitted with \pkg{R-INLA}.

In this paper we have shown an innovative approach to model fitting with INLA
and \pkg{R-INLA} which increases the number of latent models that can be fitted
with INLA. We have been able to do so by fitting conditional models on some
model parameters and combining the resulting models using simple methods for
Bayesian model averaging. We have considered the case in which conditioning is
carried out on a single parameter but our approach can be easily extended to the
case of more than one parameter.

Given that the different models can be run in parallel, this is not a real
computational burden. In our examples, 20 models seemed to be enough to obtain
good approximations. Implementing new models is very simple and the wrapper
functions included in the examples and the \pkg{INLABMA} package provide
templates to start with.

Other computationally efficient approaches for Bayesian inference on spatial 
models include, for example, \pkg{RStan} \citep{stan-software:2013}.
It provides an efficient MCMC algorithm and provides a good number of options
for Gaussian processes which can be used to implement some of the models
described in this paper. It is worth mentioning that \pkg{RStan} models are not
based on \pkg{R} code but on \pkg{C++} code that is compiled once the main
model is defined.

We have shown that this is a practical approach using different examples in
spatial statistics. Similarly, complex spatio-temporal models could be fitted
using a similar approach. However, it should be noted that our approach can be
extended to other areas.

\section*{Acknowledgements}

We would like to thank Duncan Lee and Lola Ugarte for their help and comments
on how to fit the Leroux model with \pkg{R-INLA}.


\bibliography{biblio.bib}


\end{document}
